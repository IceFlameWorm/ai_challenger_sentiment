{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4444)\n",
    "import pickle\n",
    "import numpy as np\n",
    "np.random.seed(5555)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(6666)\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from utils.dataset import DataSet, LABELS\n",
    "from models.textrnn import CuDNNGRULast as TextRNN\n",
    "from models.sentiment_base import SCompositeModel as CompositeTextRNN\n",
    "from env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_SEQS_PATH = os.path.join(CACHES_PATH, 'word_seqs_sw', 'simple')\n",
    "\n",
    "TRAIN_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'train_seqs_padded.pkl')\n",
    "VAL_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'val_seqs_padded.pkl')\n",
    "TEST_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'test_seqs_padded.pkl')\n",
    "\n",
    "SAVED_PATH = os.path.join(SAVED_MODELS_PATH, 'textrnn', 'cudnngrulast_test')\n",
    "if not os.path.exists(SAVED_PATH):\n",
    "    os.makedirs(SAVED_PATH)\n",
    "\n",
    "MODEL_PRE = 'cudnngrulast_'\n",
    "\n",
    "LR = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "FACTOR = 0.2\n",
    "\n",
    "VECTOR_DIM = 300\n",
    "EMBEDDING_PKL = os.path.join(WORD_SEQS_PATH, 'wem_%d.pkl' % VECTOR_DIM)\n",
    "RESULT_CSV = os.path.join(RESULTS_PATH, 'cudnngrulast_sw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = DataSet()\n",
    "train, val, test = raw_dataset.train, raw_dataset.val, raw_dataset.test\n",
    "\n",
    "with open(TRAIN_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    train_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(VAL_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    val_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(TEST_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    test_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(EMBEDDING_PKL, 'rb') as f:\n",
    "    embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_seq = pd.merge(train, train_seqs_padded, on='id')\n",
    "val_with_seq = pd.merge(val, val_seqs_padded, on='id')\n",
    "test_with_seq = pd.merge(test, test_seqs_padded, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/100\n",
      "105000/105000 [==============================] - 282s 3ms/step - loss: 0.3757 - acc: 0.8846 - val_loss: 0.2043 - val_acc: 0.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: _f1_monitor improved from -inf to 0.56892, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/textrnn/bicudnngrulast_test/bicudnngrulast_0.h5\n",
      "Epoch 2/100\n",
      "105000/105000 [==============================] - 283s 3ms/step - loss: 0.2227 - acc: 0.9375 - val_loss: 0.1789 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00002: _f1_monitor improved from 0.56892 to 0.61443, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/textrnn/bicudnngrulast_test/bicudnngrulast_0.h5\n",
      "Epoch 3/100\n",
      "105000/105000 [==============================] - 282s 3ms/step - loss: 0.2082 - acc: 0.9416 - val_loss: 0.1891 - val_acc: 0.9445\n",
      "\n",
      "Epoch 00003: _f1_monitor improved from 0.61443 to 0.62510, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/textrnn/bicudnngrulast_test/bicudnngrulast_0.h5\n",
      "Epoch 4/100\n",
      "105000/105000 [==============================] - 281s 3ms/step - loss: 0.2016 - acc: 0.9433 - val_loss: 0.1840 - val_acc: 0.9493\n",
      "\n",
      "Epoch 00004: _f1_monitor did not improve from 0.62510\n",
      "Epoch 5/100\n",
      " 50752/105000 [=============>................] - ETA: 2:19 - loss: 0.1948 - acc: 0.9441"
     ]
    }
   ],
   "source": [
    "y_cols = LABELS\n",
    "\n",
    "seq = 'words_seq'\n",
    "\n",
    "train_x = np.array(list(train_with_seq[seq]))\n",
    "train_y = train_with_seq[y_cols]\n",
    "val_x = np.array(list(val_with_seq[seq]))\n",
    "val_y = val_with_seq[y_cols]\n",
    "test_x = np.array(list(test_with_seq[seq]))\n",
    "\n",
    "comps = [(TextRNN, {\"max_len\":train_x.shape[1], \n",
    "                    'embedding': embedding,\n",
    "                    'mask_zero': False})] * len(y_cols)\n",
    "# comps = [(LinXiSingleModel, {\"maxlen\":train_x.shape[1]})] * len(y_cols)\n",
    "comp_model = CompositeTextRNN(comps)\n",
    "comp_model.fit(train_x, train_y, val = (val_x, val_y), y_cols = y_cols, seq = 'word_seq', saved_path = SAVED_PATH,\n",
    "               model_pre = MODEL_PRE, lr = LR, epochs = EPOCHS, batch_size = BATCH_SIZE, optimizer = RMSprop,\n",
    "               factor = FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PRE = os.path.join(SAVED_PATH, MODEL_PRE)\n",
    "# comps_1 = [(LinXiSingleModel, {'model_file': MODEL_PRE + str(i) + '.h5'}) for i in range(len(y_cols))]\n",
    "# comp_model_1 = LinXiCompositeModel(comps_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_files = [MODEL_PRE + str(i) + '.h5' for i in range(len(y_cols))]\n",
    "comp_model.load_weights(weights_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_preds = comp_model.predict(val_x)\n",
    "test_preds = comp_model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s = 0\n",
    "for i, (vy, vp) in enumerate(zip(val_y.values.T + 2, val_preds)):\n",
    "    f1 = f1_score(vy, vp, average='macro')\n",
    "    print(\"The %sth f1: %s\" % (i, f1))\n",
    "    f1s += f1\n",
    "    \n",
    "print(\"The average f1 of val is %s\" % (f1s / len(y_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test.copy()\n",
    "for index, col in enumerate(LABELS):\n",
    "    res[col] = test_preds[index] - 2\n",
    "\n",
    "res.to_csv(RESULT_CSV, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
