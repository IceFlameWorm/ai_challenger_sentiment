{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4444)\n",
    "import pickle\n",
    "import numpy as np\n",
    "np.random.seed(5555)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(6666)\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet, LABELS\n",
    "from models.own import OwnSingleModel\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from env import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_SEQS_PATH = os.path.join(CACHES_PATH, 'word_seqs_sw', 'simple')\n",
    "\n",
    "TRAIN_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'train_seqs_padded.pkl')\n",
    "VAL_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'val_seqs_padded.pkl')\n",
    "TEST_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'test_seqs_padded.pkl')\n",
    "\n",
    "VECTOR_DIM = 300\n",
    "EMBEDDING_PKL = os.path.join(WORD_SEQS_PATH, 'wem_%d.pkl' % VECTOR_DIM)\n",
    "\n",
    "MODEL_FILE = os.path.join(SAVED_MODELS_PATH, 'own', 'single.h5')\n",
    "RESULT_CSV = os.path.join(RESULTS_PATH, 'own_single.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = DataSet()\n",
    "train, val, test = raw_dataset.train, raw_dataset.val, raw_dataset.test\n",
    "\n",
    "with open(TRAIN_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    train_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(VAL_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    val_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(TEST_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    test_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(EMBEDDING_PKL, 'rb') as f:\n",
    "    embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_with_seq = pd.merge(train, train_seqs_padded, on='id')\n",
    "val_with_seq = pd.merge(val, val_seqs_padded, on='id')\n",
    "test_with_seq = pd.merge(test, test_seqs_padded, on='id')\n",
    "\n",
    "seq = 'words_seq'\n",
    "train_x = np.array(list(train_with_seq[seq]))\n",
    "val_x = np.array(list(val_with_seq[seq]))\n",
    "test_x = np.array(list(test_with_seq[seq]))\n",
    "\n",
    "y_cols = LABELS\n",
    "val_ys = []\n",
    "train_outputs = []\n",
    "val_outputs = []\n",
    "for col in y_cols:\n",
    "    train_y = train_with_seq[col] + 2\n",
    "    val_y = val_with_seq[col] + 2\n",
    "    val_ys.append(val_y)\n",
    "    train_y_onehot = to_categorical(train_y)\n",
    "    val_y_onehot = to_categorical(val_y)\n",
    "    train_outputs.append(train_y_onehot)\n",
    "    val_outputs.append(val_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1123)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1123, 300)    15000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_5 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_6 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)          (None, 100)          120600      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)          (None, 100)          120600      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)          (None, 100)          120600      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)          (None, 100)          120600      spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)          (None, 100)          120600      spatial_dropout1d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_6 (CuDNNGRU)          (None, 100)          120600      spatial_dropout1d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 100)          0           cu_dnngru_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 100)          0           cu_dnngru_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 100)          0           cu_dnngru_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 100)          0           cu_dnngru_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           cu_dnngru_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 100)          0           cu_dnngru_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100)          400         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100)          400         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100)          400         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100)          400         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100)          400         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            404         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            404         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            404         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            404         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            404         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            404         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4)            404         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            404         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            404         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            404         batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            404         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4)            404         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4)            404         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            404         batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4)            404         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 4)            404         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 4)            404         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 4)            404         batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 4)            404         batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4)            404         batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 15,734,080\n",
      "Trainable params: 15,732,880\n",
      "Non-trainable params: 1,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = OwnSingleModel(max_len = train_x.shape[1], embedding = embedding)\n",
    "model._model.summary()\n",
    "plot_model(model._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/300\n",
      "105000/105000 [==============================] - 503s 5ms/step - loss: 16.2318 - dense_1_loss: 0.7207 - dense_2_loss: 0.6603 - dense_3_loss: 0.8102 - dense_4_loss: 0.5850 - dense_5_loss: 1.0122 - dense_6_loss: 0.4067 - dense_7_loss: 0.6674 - dense_8_loss: 1.0759 - dense_9_loss: 0.6609 - dense_10_loss: 0.8854 - dense_11_loss: 0.9443 - dense_12_loss: 0.8434 - dense_13_loss: 1.0188 - dense_14_loss: 0.9278 - dense_15_loss: 1.1735 - dense_16_loss: 0.9500 - dense_17_loss: 0.8746 - dense_18_loss: 0.6948 - dense_19_loss: 0.7369 - dense_20_loss: 0.5828 - val_loss: 11.4839 - val_dense_1_loss: 0.5687 - val_dense_2_loss: 0.5384 - val_dense_3_loss: 0.6936 - val_dense_4_loss: 0.4226 - val_dense_5_loss: 0.5482 - val_dense_6_loss: 0.2736 - val_dense_7_loss: 0.4737 - val_dense_8_loss: 0.7499 - val_dense_9_loss: 0.4004 - val_dense_10_loss: 0.5034 - val_dense_11_loss: 0.5613 - val_dense_12_loss: 0.5437 - val_dense_13_loss: 0.7389 - val_dense_14_loss: 0.6072 - val_dense_15_loss: 0.9707 - val_dense_16_loss: 0.7138 - val_dense_17_loss: 0.7608 - val_dense_18_loss: 0.4858 - val_dense_19_loss: 0.5323 - val_dense_20_loss: 0.3969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: _f1_monitor improved from -inf to 0.39928, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 2/300\n",
      "105000/105000 [==============================] - 495s 5ms/step - loss: 10.5380 - dense_1_loss: 0.3315 - dense_2_loss: 0.4651 - dense_3_loss: 0.5126 - dense_4_loss: 0.3910 - dense_5_loss: 0.5557 - dense_6_loss: 0.1724 - dense_7_loss: 0.4001 - dense_8_loss: 0.7384 - dense_9_loss: 0.4142 - dense_10_loss: 0.5391 - dense_11_loss: 0.5474 - dense_12_loss: 0.5177 - dense_13_loss: 0.7201 - dense_14_loss: 0.5555 - dense_15_loss: 0.8494 - dense_16_loss: 0.6860 - dense_17_loss: 0.6992 - dense_18_loss: 0.4551 - dense_19_loss: 0.5582 - dense_20_loss: 0.4293 - val_loss: 8.6831 - val_dense_1_loss: 0.2438 - val_dense_2_loss: 0.3531 - val_dense_3_loss: 0.3517 - val_dense_4_loss: 0.3261 - val_dense_5_loss: 0.4526 - val_dense_6_loss: 0.1080 - val_dense_7_loss: 0.2929 - val_dense_8_loss: 0.6308 - val_dense_9_loss: 0.3506 - val_dense_10_loss: 0.4684 - val_dense_11_loss: 0.4557 - val_dense_12_loss: 0.4447 - val_dense_13_loss: 0.5972 - val_dense_14_loss: 0.4515 - val_dense_15_loss: 0.7063 - val_dense_16_loss: 0.5745 - val_dense_17_loss: 0.6049 - val_dense_18_loss: 0.3839 - val_dense_19_loss: 0.5118 - val_dense_20_loss: 0.3746\n",
      "\n",
      "Epoch 00002: _f1_monitor improved from 0.39928 to 0.54936, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 3/300\n",
      "105000/105000 [==============================] - 497s 5ms/step - loss: 9.2295 - dense_1_loss: 0.2501 - dense_2_loss: 0.3664 - dense_3_loss: 0.3654 - dense_4_loss: 0.3446 - dense_5_loss: 0.4985 - dense_6_loss: 0.1238 - dense_7_loss: 0.3128 - dense_8_loss: 0.6730 - dense_9_loss: 0.3830 - dense_10_loss: 0.5080 - dense_11_loss: 0.4917 - dense_12_loss: 0.4643 - dense_13_loss: 0.6225 - dense_14_loss: 0.4948 - dense_15_loss: 0.7545 - dense_16_loss: 0.6165 - dense_17_loss: 0.6276 - dense_18_loss: 0.4000 - dense_19_loss: 0.5265 - dense_20_loss: 0.4056 - val_loss: 8.1173 - val_dense_1_loss: 0.2025 - val_dense_2_loss: 0.3104 - val_dense_3_loss: 0.2962 - val_dense_4_loss: 0.3154 - val_dense_5_loss: 0.4254 - val_dense_6_loss: 0.1074 - val_dense_7_loss: 0.2576 - val_dense_8_loss: 0.5962 - val_dense_9_loss: 0.3382 - val_dense_10_loss: 0.4499 - val_dense_11_loss: 0.4253 - val_dense_12_loss: 0.4087 - val_dense_13_loss: 0.5223 - val_dense_14_loss: 0.4223 - val_dense_15_loss: 0.6674 - val_dense_16_loss: 0.5529 - val_dense_17_loss: 0.5885 - val_dense_18_loss: 0.3563 - val_dense_19_loss: 0.5040 - val_dense_20_loss: 0.3706\n",
      "\n",
      "Epoch 00003: _f1_monitor improved from 0.54936 to 0.58868, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 4/300\n",
      "105000/105000 [==============================] - 499s 5ms/step - loss: 8.7901 - dense_1_loss: 0.2302 - dense_2_loss: 0.3331 - dense_3_loss: 0.3292 - dense_4_loss: 0.3280 - dense_5_loss: 0.4761 - dense_6_loss: 0.1177 - dense_7_loss: 0.2841 - dense_8_loss: 0.6394 - dense_9_loss: 0.3751 - dense_10_loss: 0.4961 - dense_11_loss: 0.4683 - dense_12_loss: 0.4406 - dense_13_loss: 0.5793 - dense_14_loss: 0.4680 - dense_15_loss: 0.7304 - dense_16_loss: 0.5982 - dense_17_loss: 0.6125 - dense_18_loss: 0.3831 - dense_19_loss: 0.5091 - dense_20_loss: 0.3917 - val_loss: 7.9155 - val_dense_1_loss: 0.1975 - val_dense_2_loss: 0.3008 - val_dense_3_loss: 0.2834 - val_dense_4_loss: 0.2992 - val_dense_5_loss: 0.4153 - val_dense_6_loss: 0.1065 - val_dense_7_loss: 0.2438 - val_dense_8_loss: 0.5782 - val_dense_9_loss: 0.3353 - val_dense_10_loss: 0.4457 - val_dense_11_loss: 0.4167 - val_dense_12_loss: 0.3925 - val_dense_13_loss: 0.4991 - val_dense_14_loss: 0.4133 - val_dense_15_loss: 0.6601 - val_dense_16_loss: 0.5473 - val_dense_17_loss: 0.5811 - val_dense_18_loss: 0.3439 - val_dense_19_loss: 0.4992 - val_dense_20_loss: 0.3565\n",
      "\n",
      "Epoch 00004: _f1_monitor improved from 0.58868 to 0.60647, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 5/300\n",
      "105000/105000 [==============================] - 495s 5ms/step - loss: 8.5029 - dense_1_loss: 0.2170 - dense_2_loss: 0.3184 - dense_3_loss: 0.3116 - dense_4_loss: 0.3207 - dense_5_loss: 0.4582 - dense_6_loss: 0.1149 - dense_7_loss: 0.2698 - dense_8_loss: 0.6185 - dense_9_loss: 0.3670 - dense_10_loss: 0.4828 - dense_11_loss: 0.4566 - dense_12_loss: 0.4272 - dense_13_loss: 0.5560 - dense_14_loss: 0.4573 - dense_15_loss: 0.7047 - dense_16_loss: 0.5808 - dense_17_loss: 0.6015 - dense_18_loss: 0.3684 - dense_19_loss: 0.4924 - dense_20_loss: 0.3791 - val_loss: 7.7891 - val_dense_1_loss: 0.1884 - val_dense_2_loss: 0.2984 - val_dense_3_loss: 0.2805 - val_dense_4_loss: 0.2928 - val_dense_5_loss: 0.4123 - val_dense_6_loss: 0.1051 - val_dense_7_loss: 0.2387 - val_dense_8_loss: 0.5709 - val_dense_9_loss: 0.3340 - val_dense_10_loss: 0.4403 - val_dense_11_loss: 0.4087 - val_dense_12_loss: 0.3891 - val_dense_13_loss: 0.4768 - val_dense_14_loss: 0.4060 - val_dense_15_loss: 0.6436 - val_dense_16_loss: 0.5397 - val_dense_17_loss: 0.5762 - val_dense_18_loss: 0.3352 - val_dense_19_loss: 0.4940 - val_dense_20_loss: 0.3585\n",
      "\n",
      "Epoch 00005: _f1_monitor improved from 0.60647 to 0.61391, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 6/300\n",
      "105000/105000 [==============================] - 498s 5ms/step - loss: 8.2847 - dense_1_loss: 0.2108 - dense_2_loss: 0.3095 - dense_3_loss: 0.3024 - dense_4_loss: 0.3162 - dense_5_loss: 0.4436 - dense_6_loss: 0.1130 - dense_7_loss: 0.2608 - dense_8_loss: 0.6000 - dense_9_loss: 0.3626 - dense_10_loss: 0.4775 - dense_11_loss: 0.4432 - dense_12_loss: 0.4146 - dense_13_loss: 0.5344 - dense_14_loss: 0.4452 - dense_15_loss: 0.6803 - dense_16_loss: 0.5671 - dense_17_loss: 0.5914 - dense_18_loss: 0.3615 - dense_19_loss: 0.4803 - dense_20_loss: 0.3701 - val_loss: 7.7457 - val_dense_1_loss: 0.1888 - val_dense_2_loss: 0.3005 - val_dense_3_loss: 0.2785 - val_dense_4_loss: 0.2895 - val_dense_5_loss: 0.3990 - val_dense_6_loss: 0.1021 - val_dense_7_loss: 0.2328 - val_dense_8_loss: 0.5667 - val_dense_9_loss: 0.3293 - val_dense_10_loss: 0.4350 - val_dense_11_loss: 0.4093 - val_dense_12_loss: 0.3877 - val_dense_13_loss: 0.4792 - val_dense_14_loss: 0.4036 - val_dense_15_loss: 0.6361 - val_dense_16_loss: 0.5536 - val_dense_17_loss: 0.5686 - val_dense_18_loss: 0.3319 - val_dense_19_loss: 0.4951 - val_dense_20_loss: 0.3583\n",
      "\n",
      "Epoch 00006: _f1_monitor improved from 0.61391 to 0.62105, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 7/300\n",
      "105000/105000 [==============================] - 496s 5ms/step - loss: 8.0938 - dense_1_loss: 0.2040 - dense_2_loss: 0.3014 - dense_3_loss: 0.2920 - dense_4_loss: 0.3105 - dense_5_loss: 0.4324 - dense_6_loss: 0.1119 - dense_7_loss: 0.2549 - dense_8_loss: 0.5860 - dense_9_loss: 0.3591 - dense_10_loss: 0.4692 - dense_11_loss: 0.4332 - dense_12_loss: 0.4067 - dense_13_loss: 0.5217 - dense_14_loss: 0.4372 - dense_15_loss: 0.6613 - dense_16_loss: 0.5557 - dense_17_loss: 0.5831 - dense_18_loss: 0.3528 - dense_19_loss: 0.4599 - dense_20_loss: 0.3608 - val_loss: 7.7078 - val_dense_1_loss: 0.1845 - val_dense_2_loss: 0.2958 - val_dense_3_loss: 0.2764 - val_dense_4_loss: 0.2860 - val_dense_5_loss: 0.4042 - val_dense_6_loss: 0.1013 - val_dense_7_loss: 0.2338 - val_dense_8_loss: 0.5525 - val_dense_9_loss: 0.3292 - val_dense_10_loss: 0.4355 - val_dense_11_loss: 0.4103 - val_dense_12_loss: 0.3902 - val_dense_13_loss: 0.4774 - val_dense_14_loss: 0.4039 - val_dense_15_loss: 0.6249 - val_dense_16_loss: 0.5430 - val_dense_17_loss: 0.5641 - val_dense_18_loss: 0.3320 - val_dense_19_loss: 0.5016 - val_dense_20_loss: 0.3611\n",
      "\n",
      "Epoch 00007: _f1_monitor improved from 0.62105 to 0.62698, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 496s 5ms/step - loss: 7.9125 - dense_1_loss: 0.2009 - dense_2_loss: 0.2926 - dense_3_loss: 0.2829 - dense_4_loss: 0.3051 - dense_5_loss: 0.4201 - dense_6_loss: 0.1097 - dense_7_loss: 0.2476 - dense_8_loss: 0.5758 - dense_9_loss: 0.3553 - dense_10_loss: 0.4623 - dense_11_loss: 0.4242 - dense_12_loss: 0.3990 - dense_13_loss: 0.5074 - dense_14_loss: 0.4299 - dense_15_loss: 0.6429 - dense_16_loss: 0.5404 - dense_17_loss: 0.5746 - dense_18_loss: 0.3479 - dense_19_loss: 0.4442 - dense_20_loss: 0.3497 - val_loss: 7.7319 - val_dense_1_loss: 0.1848 - val_dense_2_loss: 0.3001 - val_dense_3_loss: 0.2764 - val_dense_4_loss: 0.2818 - val_dense_5_loss: 0.4056 - val_dense_6_loss: 0.1008 - val_dense_7_loss: 0.2316 - val_dense_8_loss: 0.5539 - val_dense_9_loss: 0.3282 - val_dense_10_loss: 0.4358 - val_dense_11_loss: 0.4137 - val_dense_12_loss: 0.3923 - val_dense_13_loss: 0.4763 - val_dense_14_loss: 0.4040 - val_dense_15_loss: 0.6408 - val_dense_16_loss: 0.5418 - val_dense_17_loss: 0.5623 - val_dense_18_loss: 0.3244 - val_dense_19_loss: 0.5164 - val_dense_20_loss: 0.3610\n",
      "\n",
      "Epoch 00008: _f1_monitor improved from 0.62698 to 0.63029, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 9/300\n",
      "105000/105000 [==============================] - 498s 5ms/step - loss: 7.7509 - dense_1_loss: 0.1960 - dense_2_loss: 0.2841 - dense_3_loss: 0.2771 - dense_4_loss: 0.3007 - dense_5_loss: 0.4095 - dense_6_loss: 0.1083 - dense_7_loss: 0.2426 - dense_8_loss: 0.5650 - dense_9_loss: 0.3526 - dense_10_loss: 0.4572 - dense_11_loss: 0.4159 - dense_12_loss: 0.3900 - dense_13_loss: 0.4968 - dense_14_loss: 0.4204 - dense_15_loss: 0.6302 - dense_16_loss: 0.5272 - dense_17_loss: 0.5650 - dense_18_loss: 0.3440 - dense_19_loss: 0.4276 - dense_20_loss: 0.3408 - val_loss: 7.7384 - val_dense_1_loss: 0.1881 - val_dense_2_loss: 0.3018 - val_dense_3_loss: 0.2760 - val_dense_4_loss: 0.2874 - val_dense_5_loss: 0.4038 - val_dense_6_loss: 0.0979 - val_dense_7_loss: 0.2320 - val_dense_8_loss: 0.5531 - val_dense_9_loss: 0.3242 - val_dense_10_loss: 0.4338 - val_dense_11_loss: 0.4126 - val_dense_12_loss: 0.3842 - val_dense_13_loss: 0.4711 - val_dense_14_loss: 0.3995 - val_dense_15_loss: 0.6271 - val_dense_16_loss: 0.5518 - val_dense_17_loss: 0.5618 - val_dense_18_loss: 0.3239 - val_dense_19_loss: 0.5394 - val_dense_20_loss: 0.3691\n",
      "\n",
      "Epoch 00009: _f1_monitor improved from 0.63029 to 0.63639, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 10/300\n",
      "105000/105000 [==============================] - 499s 5ms/step - loss: 7.4669 - dense_1_loss: 0.1879 - dense_2_loss: 0.2743 - dense_3_loss: 0.2644 - dense_4_loss: 0.2926 - dense_5_loss: 0.3902 - dense_6_loss: 0.1059 - dense_7_loss: 0.2340 - dense_8_loss: 0.5485 - dense_9_loss: 0.3449 - dense_10_loss: 0.4459 - dense_11_loss: 0.4033 - dense_12_loss: 0.3766 - dense_13_loss: 0.4781 - dense_14_loss: 0.4072 - dense_15_loss: 0.6008 - dense_16_loss: 0.5020 - dense_17_loss: 0.5514 - dense_18_loss: 0.3345 - dense_19_loss: 0.3975 - dense_20_loss: 0.3268 - val_loss: 7.7719 - val_dense_1_loss: 0.1857 - val_dense_2_loss: 0.3050 - val_dense_3_loss: 0.2796 - val_dense_4_loss: 0.2797 - val_dense_5_loss: 0.4085 - val_dense_6_loss: 0.0967 - val_dense_7_loss: 0.2304 - val_dense_8_loss: 0.5502 - val_dense_9_loss: 0.3245 - val_dense_10_loss: 0.4298 - val_dense_11_loss: 0.4131 - val_dense_12_loss: 0.3869 - val_dense_13_loss: 0.4742 - val_dense_14_loss: 0.4011 - val_dense_15_loss: 0.6377 - val_dense_16_loss: 0.5554 - val_dense_17_loss: 0.5635 - val_dense_18_loss: 0.3214 - val_dense_19_loss: 0.5554 - val_dense_20_loss: 0.3731\n",
      "\n",
      "Epoch 00010: _f1_monitor improved from 0.63639 to 0.63684, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 11/300\n",
      "105000/105000 [==============================] - 498s 5ms/step - loss: 7.3641 - dense_1_loss: 0.1860 - dense_2_loss: 0.2719 - dense_3_loss: 0.2584 - dense_4_loss: 0.2935 - dense_5_loss: 0.3823 - dense_6_loss: 0.1043 - dense_7_loss: 0.2299 - dense_8_loss: 0.5437 - dense_9_loss: 0.3419 - dense_10_loss: 0.4413 - dense_11_loss: 0.3941 - dense_12_loss: 0.3719 - dense_13_loss: 0.4705 - dense_14_loss: 0.3993 - dense_15_loss: 0.5926 - dense_16_loss: 0.4951 - dense_17_loss: 0.5474 - dense_18_loss: 0.3314 - dense_19_loss: 0.3887 - dense_20_loss: 0.3201 - val_loss: 7.7940 - val_dense_1_loss: 0.1866 - val_dense_2_loss: 0.3063 - val_dense_3_loss: 0.2820 - val_dense_4_loss: 0.2778 - val_dense_5_loss: 0.4092 - val_dense_6_loss: 0.0962 - val_dense_7_loss: 0.2282 - val_dense_8_loss: 0.5491 - val_dense_9_loss: 0.3240 - val_dense_10_loss: 0.4300 - val_dense_11_loss: 0.4135 - val_dense_12_loss: 0.3878 - val_dense_13_loss: 0.4768 - val_dense_14_loss: 0.4020 - val_dense_15_loss: 0.6414 - val_dense_16_loss: 0.5561 - val_dense_17_loss: 0.5614 - val_dense_18_loss: 0.3215 - val_dense_19_loss: 0.5681 - val_dense_20_loss: 0.3761\n",
      "\n",
      "Epoch 00011: _f1_monitor improved from 0.63684 to 0.63971, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_outputs, \n",
    "          validation_data = (val_x, val_outputs),\n",
    "          model_file = MODEL_FILE\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model.load_weights(MODEL_FILE)\n",
    "val_probs = model.predict(val_x)\n",
    "test_probs = model.predict(test_x)\n",
    "\n",
    "val_preds = list(map(lambda x: np.argmax(x, axis = -1), val_probs))\n",
    "# val_preds = np.argmax(val_probs, axis = 1)\n",
    "# test_preds = list(map(lambda x: np.argmax(x, axis = -1), test_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th f1: 0.605466622247453\n",
      "The 1th f1: 0.502159358188295\n",
      "The 2th f1: 0.626253418681543\n",
      "The 3th f1: 0.5627216442135571\n",
      "The 4th f1: 0.76670829521768\n",
      "The 5th f1: 0.5170212115127293\n",
      "The 6th f1: 0.6424132286511315\n",
      "The 7th f1: 0.7493463835096147\n",
      "The 8th f1: 0.6883904199916078\n",
      "The 9th f1: 0.5938356266491976\n",
      "The 10th f1: 0.6806562906095373\n",
      "The 11th f1: 0.7260506256647516\n",
      "The 12th f1: 0.7250364915288556\n",
      "The 13th f1: 0.6963565770584659\n",
      "The 14th f1: 0.6591619739738395\n",
      "The 15th f1: 0.687874474323913\n",
      "The 16th f1: 0.46662034314991496\n",
      "The 17th f1: 0.6724100280515015\n",
      "The 18th f1: 0.5527347542662917\n",
      "The 19th f1: 0.6730820552972366\n",
      "The average f1 of val is 0.6397149911393558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1s = 0\n",
    "for i, (vy, vp) in enumerate(zip(val_ys, val_preds)):\n",
    "    f1 = f1_score(vy, vp, average='macro')\n",
    "    print(\"The %sth f1: %s\" % (i, f1))\n",
    "    f1s += f1\n",
    "    \n",
    "print(\"The average f1 of val is %s\" % (f1s / len(y_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
