{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4444)\n",
    "import pickle\n",
    "import numpy as np\n",
    "np.random.seed(5555)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(6666)\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet, LABELS\n",
    "from models.own import OwnSingleModel\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from env import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_SEQS_PATH = os.path.join(CACHES_PATH, 'word_seqs_sw', 'simple')\n",
    "\n",
    "TRAIN_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'train_seqs_padded.pkl')\n",
    "VAL_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'val_seqs_padded.pkl')\n",
    "TEST_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'test_seqs_padded.pkl')\n",
    "\n",
    "VECTOR_DIM = 300\n",
    "EMBEDDING_PKL = os.path.join(WORD_SEQS_PATH, 'wem_%d.pkl' % VECTOR_DIM)\n",
    "\n",
    "MODEL_FILE = os.path.join(SAVED_MODELS_PATH, 'own', 'single.h5')\n",
    "RESULT_CSV = os.path.join(RESULTS_PATH, 'own_single.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = DataSet()\n",
    "train, val, test = raw_dataset.train, raw_dataset.val, raw_dataset.test\n",
    "\n",
    "with open(TRAIN_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    train_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(VAL_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    val_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(TEST_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    test_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(EMBEDDING_PKL, 'rb') as f:\n",
    "    embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_with_seq = pd.merge(train, train_seqs_padded, on='id')\n",
    "val_with_seq = pd.merge(val, val_seqs_padded, on='id')\n",
    "test_with_seq = pd.merge(test, test_seqs_padded, on='id')\n",
    "\n",
    "seq = 'words_seq'\n",
    "train_x = np.array(list(train_with_seq[seq]))\n",
    "val_x = np.array(list(val_with_seq[seq]))\n",
    "test_x = np.array(list(test_with_seq[seq]))\n",
    "\n",
    "y_cols = LABELS\n",
    "val_ys = []\n",
    "train_outputs = []\n",
    "val_outputs = []\n",
    "for col in y_cols:\n",
    "    train_y = train_with_seq[col] + 2\n",
    "    val_y = val_with_seq[col] + 2\n",
    "    val_ys.append(val_y)\n",
    "    train_y_onehot = to_categorical(train_y)\n",
    "    val_y_onehot = to_categorical(val_y)\n",
    "    train_outputs.append(train_y_onehot)\n",
    "    val_outputs.append(val_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1123)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1123, 300)    15000000    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 1123, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_1 (CuDNNGRU)          (None, 1123, 300)    541800      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_3 (CuDNNGRU)          (None, 1123, 300)    541800      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_5 (CuDNNGRU)          (None, 1123, 300)    541800      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_7 (CuDNNGRU)          (None, 1123, 300)    541800      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_9 (CuDNNGRU)          (None, 1123, 300)    541800      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_11 (CuDNNGRU)         (None, 1123, 300)    541800      spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_2 (CuDNNGRU)          (None, 300)          541800      cu_dnngru_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_4 (CuDNNGRU)          (None, 300)          541800      cu_dnngru_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_6 (CuDNNGRU)          (None, 300)          541800      cu_dnngru_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_8 (CuDNNGRU)          (None, 300)          541800      cu_dnngru_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_10 (CuDNNGRU)         (None, 300)          541800      cu_dnngru_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnngru_12 (CuDNNGRU)         (None, 300)          541800      cu_dnngru_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           cu_dnngru_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           cu_dnngru_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           cu_dnngru_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 300)          0           cu_dnngru_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 300)          0           cu_dnngru_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 300)          0           cu_dnngru_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 300)          1200        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 300)          1200        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 300)          1200        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 300)          1200        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 300)          1200        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 300)          1200        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4)            1204        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4)            1204        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            1204        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            1204        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            1204        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            1204        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 4)            1204        batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4)            1204        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 4)            1204        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 4)            1204        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            1204        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4)            1204        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4)            1204        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            1204        batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 4)            1204        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 4)            1204        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 4)            1204        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 4)            1204        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 4)            1204        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 4)            1204        batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 21,532,880\n",
      "Trainable params: 21,529,280\n",
      "Non-trainable params: 3,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = OwnSingleModel(max_len = train_x.shape[1], embedding = embedding)\n",
    "model._model.summary()\n",
    "plot_model(model._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/300\n",
      "105000/105000 [==============================] - 1447s 14ms/step - loss: 12.9082 - dense_1_loss: 0.4764 - dense_2_loss: 0.5348 - dense_3_loss: 0.5852 - dense_4_loss: 0.4704 - dense_5_loss: 0.7286 - dense_6_loss: 0.2684 - dense_7_loss: 0.4943 - dense_8_loss: 0.8353 - dense_9_loss: 0.5247 - dense_10_loss: 0.6607 - dense_11_loss: 0.7634 - dense_12_loss: 0.6936 - dense_13_loss: 0.8721 - dense_14_loss: 0.7714 - dense_15_loss: 0.9702 - dense_16_loss: 0.7871 - dense_17_loss: 0.7755 - dense_18_loss: 0.5498 - dense_19_loss: 0.6522 - dense_20_loss: 0.4942 - val_loss: 8.0671 - val_dense_1_loss: 0.1987 - val_dense_2_loss: 0.3252 - val_dense_3_loss: 0.2803 - val_dense_4_loss: 0.3051 - val_dense_5_loss: 0.4312 - val_dense_6_loss: 0.1072 - val_dense_7_loss: 0.2450 - val_dense_8_loss: 0.5754 - val_dense_9_loss: 0.3311 - val_dense_10_loss: 0.4433 - val_dense_11_loss: 0.4384 - val_dense_12_loss: 0.4204 - val_dense_13_loss: 0.5442 - val_dense_14_loss: 0.4363 - val_dense_15_loss: 0.6477 - val_dense_16_loss: 0.5550 - val_dense_17_loss: 0.5713 - val_dense_18_loss: 0.3352 - val_dense_19_loss: 0.5163 - val_dense_20_loss: 0.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: _f1_monitor improved from -inf to 0.60817, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 2/300\n",
      "105000/105000 [==============================] - 1450s 14ms/step - loss: 8.3144 - dense_1_loss: 0.2159 - dense_2_loss: 0.3246 - dense_3_loss: 0.3006 - dense_4_loss: 0.3069 - dense_5_loss: 0.4463 - dense_6_loss: 0.1018 - dense_7_loss: 0.2588 - dense_8_loss: 0.5820 - dense_9_loss: 0.3520 - dense_10_loss: 0.4675 - dense_11_loss: 0.4630 - dense_12_loss: 0.4371 - dense_13_loss: 0.5575 - dense_14_loss: 0.4610 - dense_15_loss: 0.6632 - dense_16_loss: 0.5647 - dense_17_loss: 0.5769 - dense_18_loss: 0.3379 - dense_19_loss: 0.5136 - dense_20_loss: 0.3832 - val_loss: 7.5465 - val_dense_1_loss: 0.1747 - val_dense_2_loss: 0.2955 - val_dense_3_loss: 0.2581 - val_dense_4_loss: 0.2711 - val_dense_5_loss: 0.4245 - val_dense_6_loss: 0.0823 - val_dense_7_loss: 0.2191 - val_dense_8_loss: 0.5433 - val_dense_9_loss: 0.3216 - val_dense_10_loss: 0.4443 - val_dense_11_loss: 0.4169 - val_dense_12_loss: 0.3847 - val_dense_13_loss: 0.4939 - val_dense_14_loss: 0.4119 - val_dense_15_loss: 0.5926 - val_dense_16_loss: 0.5167 - val_dense_17_loss: 0.5360 - val_dense_18_loss: 0.3027 - val_dense_19_loss: 0.5127 - val_dense_20_loss: 0.3440\n",
      "\n",
      "Epoch 00002: _f1_monitor improved from 0.60817 to 0.65011, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 3/300\n",
      "105000/105000 [==============================] - 1450s 14ms/step - loss: 7.7524 - dense_1_loss: 0.1968 - dense_2_loss: 0.3016 - dense_3_loss: 0.2787 - dense_4_loss: 0.2832 - dense_5_loss: 0.4148 - dense_6_loss: 0.0895 - dense_7_loss: 0.2326 - dense_8_loss: 0.5468 - dense_9_loss: 0.3344 - dense_10_loss: 0.4429 - dense_11_loss: 0.4293 - dense_12_loss: 0.4040 - dense_13_loss: 0.5038 - dense_14_loss: 0.4223 - dense_15_loss: 0.6181 - dense_16_loss: 0.5326 - dense_17_loss: 0.5505 - dense_18_loss: 0.3189 - dense_19_loss: 0.4889 - dense_20_loss: 0.3627 - val_loss: 7.2861 - val_dense_1_loss: 0.1711 - val_dense_2_loss: 0.2947 - val_dense_3_loss: 0.2621 - val_dense_4_loss: 0.2612 - val_dense_5_loss: 0.3786 - val_dense_6_loss: 0.0786 - val_dense_7_loss: 0.2262 - val_dense_8_loss: 0.5236 - val_dense_9_loss: 0.3150 - val_dense_10_loss: 0.4234 - val_dense_11_loss: 0.3981 - val_dense_12_loss: 0.3674 - val_dense_13_loss: 0.4557 - val_dense_14_loss: 0.3742 - val_dense_15_loss: 0.5953 - val_dense_16_loss: 0.5083 - val_dense_17_loss: 0.5284 - val_dense_18_loss: 0.2987 - val_dense_19_loss: 0.4840 - val_dense_20_loss: 0.3416\n",
      "\n",
      "Epoch 00003: _f1_monitor improved from 0.65011 to 0.67334, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 4/300\n",
      "105000/105000 [==============================] - 1450s 14ms/step - loss: 7.4070 - dense_1_loss: 0.1867 - dense_2_loss: 0.2874 - dense_3_loss: 0.2627 - dense_4_loss: 0.2715 - dense_5_loss: 0.3955 - dense_6_loss: 0.0860 - dense_7_loss: 0.2193 - dense_8_loss: 0.5219 - dense_9_loss: 0.3248 - dense_10_loss: 0.4299 - dense_11_loss: 0.4063 - dense_12_loss: 0.3847 - dense_13_loss: 0.4804 - dense_14_loss: 0.4010 - dense_15_loss: 0.5884 - dense_16_loss: 0.5071 - dense_17_loss: 0.5319 - dense_18_loss: 0.3071 - dense_19_loss: 0.4677 - dense_20_loss: 0.3465 - val_loss: 7.1930 - val_dense_1_loss: 0.1806 - val_dense_2_loss: 0.2971 - val_dense_3_loss: 0.2571 - val_dense_4_loss: 0.2592 - val_dense_5_loss: 0.3860 - val_dense_6_loss: 0.0756 - val_dense_7_loss: 0.2048 - val_dense_8_loss: 0.5244 - val_dense_9_loss: 0.3102 - val_dense_10_loss: 0.4103 - val_dense_11_loss: 0.3931 - val_dense_12_loss: 0.3645 - val_dense_13_loss: 0.4540 - val_dense_14_loss: 0.3699 - val_dense_15_loss: 0.5674 - val_dense_16_loss: 0.5028 - val_dense_17_loss: 0.5256 - val_dense_18_loss: 0.2976 - val_dense_19_loss: 0.4802 - val_dense_20_loss: 0.3324\n",
      "\n",
      "Epoch 00004: _f1_monitor improved from 0.67334 to 0.67771, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 5/300\n",
      "105000/105000 [==============================] - 1452s 14ms/step - loss: 7.1495 - dense_1_loss: 0.1777 - dense_2_loss: 0.2764 - dense_3_loss: 0.2522 - dense_4_loss: 0.2630 - dense_5_loss: 0.3794 - dense_6_loss: 0.0816 - dense_7_loss: 0.2099 - dense_8_loss: 0.5076 - dense_9_loss: 0.3187 - dense_10_loss: 0.4213 - dense_11_loss: 0.3922 - dense_12_loss: 0.3698 - dense_13_loss: 0.4621 - dense_14_loss: 0.3865 - dense_15_loss: 0.5672 - dense_16_loss: 0.4876 - dense_17_loss: 0.5170 - dense_18_loss: 0.3009 - dense_19_loss: 0.4465 - dense_20_loss: 0.3318 - val_loss: 7.2101 - val_dense_1_loss: 0.1717 - val_dense_2_loss: 0.2945 - val_dense_3_loss: 0.2584 - val_dense_4_loss: 0.2602 - val_dense_5_loss: 0.3822 - val_dense_6_loss: 0.0754 - val_dense_7_loss: 0.2134 - val_dense_8_loss: 0.5198 - val_dense_9_loss: 0.3129 - val_dense_10_loss: 0.4083 - val_dense_11_loss: 0.3818 - val_dense_12_loss: 0.3626 - val_dense_13_loss: 0.4550 - val_dense_14_loss: 0.3657 - val_dense_15_loss: 0.5691 - val_dense_16_loss: 0.5152 - val_dense_17_loss: 0.5317 - val_dense_18_loss: 0.2969 - val_dense_19_loss: 0.5014 - val_dense_20_loss: 0.3338\n",
      "\n",
      "Epoch 00005: _f1_monitor improved from 0.67771 to 0.68161, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 6/300\n",
      "105000/105000 [==============================] - 1452s 14ms/step - loss: 6.8965 - dense_1_loss: 0.1716 - dense_2_loss: 0.2654 - dense_3_loss: 0.2425 - dense_4_loss: 0.2567 - dense_5_loss: 0.3628 - dense_6_loss: 0.0784 - dense_7_loss: 0.2021 - dense_8_loss: 0.4916 - dense_9_loss: 0.3132 - dense_10_loss: 0.4090 - dense_11_loss: 0.3764 - dense_12_loss: 0.3579 - dense_13_loss: 0.4472 - dense_14_loss: 0.3735 - dense_15_loss: 0.5470 - dense_16_loss: 0.4668 - dense_17_loss: 0.5004 - dense_18_loss: 0.2944 - dense_19_loss: 0.4201 - dense_20_loss: 0.3193 - val_loss: 7.2938 - val_dense_1_loss: 0.1750 - val_dense_2_loss: 0.2967 - val_dense_3_loss: 0.2628 - val_dense_4_loss: 0.2574 - val_dense_5_loss: 0.3926 - val_dense_6_loss: 0.0761 - val_dense_7_loss: 0.2060 - val_dense_8_loss: 0.5226 - val_dense_9_loss: 0.3136 - val_dense_10_loss: 0.4070 - val_dense_11_loss: 0.3885 - val_dense_12_loss: 0.3672 - val_dense_13_loss: 0.4541 - val_dense_14_loss: 0.3657 - val_dense_15_loss: 0.5866 - val_dense_16_loss: 0.5271 - val_dense_17_loss: 0.5387 - val_dense_18_loss: 0.3016 - val_dense_19_loss: 0.5103 - val_dense_20_loss: 0.3441\n",
      "\n",
      "Epoch 00006: _f1_monitor did not improve from 0.68161\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 7/300\n",
      "105000/105000 [==============================] - 1451s 14ms/step - loss: 6.3689 - dense_1_loss: 0.1556 - dense_2_loss: 0.2445 - dense_3_loss: 0.2194 - dense_4_loss: 0.2435 - dense_5_loss: 0.3280 - dense_6_loss: 0.0728 - dense_7_loss: 0.1843 - dense_8_loss: 0.4569 - dense_9_loss: 0.2948 - dense_10_loss: 0.3837 - dense_11_loss: 0.3500 - dense_12_loss: 0.3304 - dense_13_loss: 0.4139 - dense_14_loss: 0.3466 - dense_15_loss: 0.5046 - dense_16_loss: 0.4258 - dense_17_loss: 0.4683 - dense_18_loss: 0.2785 - dense_19_loss: 0.3737 - dense_20_loss: 0.2937 - val_loss: 7.3064 - val_dense_1_loss: 0.1745 - val_dense_2_loss: 0.3007 - val_dense_3_loss: 0.2662 - val_dense_4_loss: 0.2535 - val_dense_5_loss: 0.3904 - val_dense_6_loss: 0.0746 - val_dense_7_loss: 0.1999 - val_dense_8_loss: 0.5189 - val_dense_9_loss: 0.3128 - val_dense_10_loss: 0.4041 - val_dense_11_loss: 0.3923 - val_dense_12_loss: 0.3672 - val_dense_13_loss: 0.4561 - val_dense_14_loss: 0.3674 - val_dense_15_loss: 0.5798 - val_dense_16_loss: 0.5365 - val_dense_17_loss: 0.5411 - val_dense_18_loss: 0.2974 - val_dense_19_loss: 0.5353 - val_dense_20_loss: 0.3380\n",
      "\n",
      "Epoch 00007: _f1_monitor improved from 0.68161 to 0.68523, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 1452s 14ms/step - loss: 6.1666 - dense_1_loss: 0.1497 - dense_2_loss: 0.2384 - dense_3_loss: 0.2112 - dense_4_loss: 0.2372 - dense_5_loss: 0.3160 - dense_6_loss: 0.0708 - dense_7_loss: 0.1769 - dense_8_loss: 0.4425 - dense_9_loss: 0.2878 - dense_10_loss: 0.3764 - dense_11_loss: 0.3395 - dense_12_loss: 0.3198 - dense_13_loss: 0.4000 - dense_14_loss: 0.3359 - dense_15_loss: 0.4904 - dense_16_loss: 0.4094 - dense_17_loss: 0.4563 - dense_18_loss: 0.2699 - dense_19_loss: 0.3561 - dense_20_loss: 0.2825 - val_loss: 7.3892 - val_dense_1_loss: 0.1812 - val_dense_2_loss: 0.3078 - val_dense_3_loss: 0.2706 - val_dense_4_loss: 0.2525 - val_dense_5_loss: 0.3935 - val_dense_6_loss: 0.0738 - val_dense_7_loss: 0.2049 - val_dense_8_loss: 0.5252 - val_dense_9_loss: 0.3137 - val_dense_10_loss: 0.4058 - val_dense_11_loss: 0.3981 - val_dense_12_loss: 0.3718 - val_dense_13_loss: 0.4615 - val_dense_14_loss: 0.3697 - val_dense_15_loss: 0.5856 - val_dense_16_loss: 0.5377 - val_dense_17_loss: 0.5452 - val_dense_18_loss: 0.2980 - val_dense_19_loss: 0.5488 - val_dense_20_loss: 0.3437\n",
      "\n",
      "Epoch 00008: _f1_monitor improved from 0.68523 to 0.68701, saving model to /root/mounted/projects/ai_challenger_sentiment/data/saved_models/own/single.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 9/300\n",
      "105000/105000 [==============================] - 1451s 14ms/step - loss: 5.9977 - dense_1_loss: 0.1431 - dense_2_loss: 0.2293 - dense_3_loss: 0.2023 - dense_4_loss: 0.2313 - dense_5_loss: 0.3059 - dense_6_loss: 0.0681 - dense_7_loss: 0.1715 - dense_8_loss: 0.4297 - dense_9_loss: 0.2816 - dense_10_loss: 0.3676 - dense_11_loss: 0.3303 - dense_12_loss: 0.3138 - dense_13_loss: 0.3900 - dense_14_loss: 0.3290 - dense_15_loss: 0.4781 - dense_16_loss: 0.3972 - dense_17_loss: 0.4463 - dense_18_loss: 0.2666 - dense_19_loss: 0.3396 - dense_20_loss: 0.2764 - val_loss: 7.4086 - val_dense_1_loss: 0.1798 - val_dense_2_loss: 0.3102 - val_dense_3_loss: 0.2718 - val_dense_4_loss: 0.2520 - val_dense_5_loss: 0.3962 - val_dense_6_loss: 0.0739 - val_dense_7_loss: 0.2024 - val_dense_8_loss: 0.5249 - val_dense_9_loss: 0.3147 - val_dense_10_loss: 0.4065 - val_dense_11_loss: 0.3964 - val_dense_12_loss: 0.3721 - val_dense_13_loss: 0.4620 - val_dense_14_loss: 0.3703 - val_dense_15_loss: 0.5856 - val_dense_16_loss: 0.5453 - val_dense_17_loss: 0.5476 - val_dense_18_loss: 0.2987 - val_dense_19_loss: 0.5543 - val_dense_20_loss: 0.3440\n",
      "\n",
      "Epoch 00009: _f1_monitor did not improve from 0.68701\n",
      "Epoch 10/300\n",
      "105000/105000 [==============================] - 1452s 14ms/step - loss: 5.9566 - dense_1_loss: 0.1417 - dense_2_loss: 0.2283 - dense_3_loss: 0.2006 - dense_4_loss: 0.2307 - dense_5_loss: 0.3026 - dense_6_loss: 0.0679 - dense_7_loss: 0.1699 - dense_8_loss: 0.4284 - dense_9_loss: 0.2801 - dense_10_loss: 0.3627 - dense_11_loss: 0.3287 - dense_12_loss: 0.3092 - dense_13_loss: 0.3897 - dense_14_loss: 0.3259 - dense_15_loss: 0.4741 - dense_16_loss: 0.3967 - dense_17_loss: 0.4454 - dense_18_loss: 0.2646 - dense_19_loss: 0.3364 - dense_20_loss: 0.2729 - val_loss: 7.4272 - val_dense_1_loss: 0.1792 - val_dense_2_loss: 0.3099 - val_dense_3_loss: 0.2715 - val_dense_4_loss: 0.2521 - val_dense_5_loss: 0.3973 - val_dense_6_loss: 0.0740 - val_dense_7_loss: 0.2026 - val_dense_8_loss: 0.5253 - val_dense_9_loss: 0.3153 - val_dense_10_loss: 0.4057 - val_dense_11_loss: 0.3986 - val_dense_12_loss: 0.3733 - val_dense_13_loss: 0.4635 - val_dense_14_loss: 0.3709 - val_dense_15_loss: 0.5864 - val_dense_16_loss: 0.5470 - val_dense_17_loss: 0.5496 - val_dense_18_loss: 0.2989 - val_dense_19_loss: 0.5604 - val_dense_20_loss: 0.3457\n",
      "\n",
      "Epoch 00010: _f1_monitor did not improve from 0.68701\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_outputs, \n",
    "          validation_data = (val_x, val_outputs),\n",
    "          model_file = MODEL_FILE\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model.load_weights(MODEL_FILE)\n",
    "val_probs = model.predict(val_x)\n",
    "test_probs = model.predict(test_x)\n",
    "\n",
    "val_preds = list(map(lambda x: np.argmax(x, axis = -1), val_probs))\n",
    "# val_preds = np.argmax(val_probs, axis = 1)\n",
    "# test_preds = list(map(lambda x: np.argmax(x, axis = -1), test_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th f1: 0.6425371792941685\n",
      "The 1th f1: 0.5141235370954264\n",
      "The 2th f1: 0.695493744582423\n",
      "The 3th f1: 0.640088365444609\n",
      "The 4th f1: 0.7837327279181838\n",
      "The 5th f1: 0.7172420553778831\n",
      "The 6th f1: 0.7369990377189853\n",
      "The 7th f1: 0.7621560943307086\n",
      "The 8th f1: 0.7063024045200141\n",
      "The 9th f1: 0.6660590777499031\n",
      "The 10th f1: 0.6903950824341004\n",
      "The 11th f1: 0.7494882070247237\n",
      "The 12th f1: 0.7371395409067902\n",
      "The 13th f1: 0.7298458633368893\n",
      "The 14th f1: 0.7012713630749309\n",
      "The 15th f1: 0.7054886126198998\n",
      "The 16th f1: 0.55434074801027\n",
      "The 17th f1: 0.7307448277835289\n",
      "The 18th f1: 0.5632610454578739\n",
      "The 19th f1: 0.7135036753532185\n",
      "The average f1 of val is 0.6870106595017266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "f1s = 0\n",
    "for i, (vy, vp) in enumerate(zip(val_ys, val_preds)):\n",
    "    f1 = f1_score(vy, vp, average='macro')\n",
    "    print(\"The %sth f1: %s\" % (i, f1))\n",
    "    f1s += f1\n",
    "    \n",
    "print(\"The average f1 of val is %s\" % (f1s / len(y_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
