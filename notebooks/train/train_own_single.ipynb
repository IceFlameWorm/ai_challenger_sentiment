{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4444)\n",
    "import pickle\n",
    "import numpy as np\n",
    "np.random.seed(5555)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(6666)\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet, LABELS\n",
    "from models.own import OwnSingleModel\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from env import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_SEQS_PATH = os.path.join(CACHES_PATH, 'word_seqs/simple')\n",
    "\n",
    "TRAIN_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'train_seqs_padded.pkl')\n",
    "VAL_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'val_seqs_padded.pkl')\n",
    "TEST_SEQS_PADDED_PKL = os.path.join(WORD_SEQS_PATH, 'test_seqs_padded.pkl')\n",
    "\n",
    "EMBEDDING_PKL = os.path.join(WORD_SEQS_PATH, 'wem.pkl')\n",
    "\n",
    "MODEL_FILE = os.path.join(SAVED_MODELS_PATH, 'own/single.h5')\n",
    "RESULT_CSV = os.path.join(RESULTS_PATH, 'own_single.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = DataSet()\n",
    "train, val, test = raw_dataset.train, raw_dataset.val, raw_dataset.test\n",
    "\n",
    "with open(TRAIN_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    train_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(VAL_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    val_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(TEST_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    test_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(EMBEDDING_PKL, 'rb') as f:\n",
    "    embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_with_seq = pd.merge(train, train_seqs_padded, on='id')\n",
    "val_with_seq = pd.merge(val, val_seqs_padded, on='id')\n",
    "test_with_seq = pd.merge(test, test_seqs_padded, on='id')\n",
    "\n",
    "seq = 'words_seq'\n",
    "train_x = np.array(list(train_with_seq[seq]))\n",
    "val_x = np.array(list(val_with_seq[seq]))\n",
    "test_x = np.array(list(test_with_seq[seq]))\n",
    "\n",
    "y_cols = LABELS\n",
    "val_ys = []\n",
    "train_outputs = []\n",
    "val_outputs = []\n",
    "for col in y_cols:\n",
    "    train_y = train_with_seq[col] + 2\n",
    "    val_y = val_with_seq[col] + 2\n",
    "    val_ys.append(val_y)\n",
    "    train_y_onehot = to_categorical(train_y)\n",
    "    val_y_onehot = to_categorical(val_y)\n",
    "    train_outputs.append(train_y_onehot)\n",
    "    val_outputs.append(val_y_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OwnSingleModel(max_len = train_x.shape[1], embedding = embedding)\n",
    "# model._model.summary()\n",
    "plot_model(model._model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/300\n",
      "105000/105000 [==============================] - 43s 411us/step - loss: 17.3045 - dense_1_loss: 0.6214 - dense_2_loss: 0.6562 - dense_3_loss: 0.7345 - dense_4_loss: 0.6362 - dense_5_loss: 1.1326 - dense_6_loss: 0.4425 - dense_7_loss: 0.7093 - dense_8_loss: 1.2208 - dense_9_loss: 0.8122 - dense_10_loss: 1.0081 - dense_11_loss: 0.9598 - dense_12_loss: 0.8120 - dense_13_loss: 0.9823 - dense_14_loss: 0.8724 - dense_15_loss: 1.1439 - dense_16_loss: 1.0360 - dense_17_loss: 0.9189 - dense_18_loss: 0.8093 - dense_19_loss: 0.9100 - dense_20_loss: 0.8862 - val_loss: 14.0445 - val_dense_1_loss: 0.3644 - val_dense_2_loss: 0.5289 - val_dense_3_loss: 0.4880 - val_dense_4_loss: 0.4968 - val_dense_5_loss: 0.9122 - val_dense_6_loss: 0.3046 - val_dense_7_loss: 0.5404 - val_dense_8_loss: 1.0961 - val_dense_9_loss: 0.6175 - val_dense_10_loss: 0.8034 - val_dense_11_loss: 0.7384 - val_dense_12_loss: 0.6410 - val_dense_13_loss: 0.8444 - val_dense_14_loss: 0.6528 - val_dense_15_loss: 1.0731 - val_dense_16_loss: 0.9258 - val_dense_17_loss: 0.8081 - val_dense_18_loss: 0.6350 - val_dense_19_loss: 0.8269 - val_dense_20_loss: 0.7468\n",
      "Epoch 2/300\n",
      "105000/105000 [==============================] - 41s 386us/step - loss: 13.0333 - dense_1_loss: 0.3153 - dense_2_loss: 0.5205 - dense_3_loss: 0.4532 - dense_4_loss: 0.4921 - dense_5_loss: 0.7684 - dense_6_loss: 0.3089 - dense_7_loss: 0.4621 - dense_8_loss: 0.9670 - dense_9_loss: 0.5056 - dense_10_loss: 0.6748 - dense_11_loss: 0.6701 - dense_12_loss: 0.6147 - dense_13_loss: 0.8479 - dense_14_loss: 0.6341 - dense_15_loss: 0.9814 - dense_16_loss: 0.9037 - dense_17_loss: 0.7741 - dense_18_loss: 0.6219 - dense_19_loss: 0.7996 - dense_20_loss: 0.7180 - val_loss: 12.2657 - val_dense_1_loss: 0.2705 - val_dense_2_loss: 0.4984 - val_dense_3_loss: 0.4056 - val_dense_4_loss: 0.4937 - val_dense_5_loss: 0.6841 - val_dense_6_loss: 0.3064 - val_dense_7_loss: 0.4243 - val_dense_8_loss: 0.8924 - val_dense_9_loss: 0.4498 - val_dense_10_loss: 0.5826 - val_dense_11_loss: 0.6269 - val_dense_12_loss: 0.6019 - val_dense_13_loss: 0.8168 - val_dense_14_loss: 0.5986 - val_dense_15_loss: 0.9157 - val_dense_16_loss: 0.8832 - val_dense_17_loss: 0.7474 - val_dense_18_loss: 0.6243 - val_dense_19_loss: 0.7641 - val_dense_20_loss: 0.6790\n",
      "Epoch 3/300\n",
      "105000/105000 [==============================] - 41s 386us/step - loss: 11.7814 - dense_1_loss: 0.2688 - dense_2_loss: 0.4739 - dense_3_loss: 0.3939 - dense_4_loss: 0.4858 - dense_5_loss: 0.6474 - dense_6_loss: 0.2997 - dense_7_loss: 0.4044 - dense_8_loss: 0.8409 - dense_9_loss: 0.4245 - dense_10_loss: 0.5455 - dense_11_loss: 0.6034 - dense_12_loss: 0.5827 - dense_13_loss: 0.8158 - dense_14_loss: 0.5899 - dense_15_loss: 0.8746 - dense_16_loss: 0.8578 - dense_17_loss: 0.7080 - dense_18_loss: 0.5671 - dense_19_loss: 0.7409 - dense_20_loss: 0.6562 - val_loss: 11.3600 - val_dense_1_loss: 0.2538 - val_dense_2_loss: 0.4383 - val_dense_3_loss: 0.3782 - val_dense_4_loss: 0.4866 - val_dense_5_loss: 0.6229 - val_dense_6_loss: 0.2937 - val_dense_7_loss: 0.3960 - val_dense_8_loss: 0.8197 - val_dense_9_loss: 0.4104 - val_dense_10_loss: 0.5210 - val_dense_11_loss: 0.5870 - val_dense_12_loss: 0.5787 - val_dense_13_loss: 0.7860 - val_dense_14_loss: 0.5691 - val_dense_15_loss: 0.8510 - val_dense_16_loss: 0.8365 - val_dense_17_loss: 0.6888 - val_dense_18_loss: 0.4996 - val_dense_19_loss: 0.7198 - val_dense_20_loss: 0.6230\n",
      "Epoch 4/300\n",
      "105000/105000 [==============================] - 41s 386us/step - loss: 10.9736 - dense_1_loss: 0.2545 - dense_2_loss: 0.3982 - dense_3_loss: 0.3701 - dense_4_loss: 0.4731 - dense_5_loss: 0.5968 - dense_6_loss: 0.2871 - dense_7_loss: 0.3841 - dense_8_loss: 0.7749 - dense_9_loss: 0.3962 - dense_10_loss: 0.5059 - dense_11_loss: 0.5682 - dense_12_loss: 0.5608 - dense_13_loss: 0.7843 - dense_14_loss: 0.5603 - dense_15_loss: 0.8181 - dense_16_loss: 0.8021 - dense_17_loss: 0.6665 - dense_18_loss: 0.4708 - dense_19_loss: 0.6971 - dense_20_loss: 0.6044 - val_loss: 10.7586 - val_dense_1_loss: 0.2424 - val_dense_2_loss: 0.3753 - val_dense_3_loss: 0.3607 - val_dense_4_loss: 0.4584 - val_dense_5_loss: 0.5888 - val_dense_6_loss: 0.2773 - val_dense_7_loss: 0.3841 - val_dense_8_loss: 0.7649 - val_dense_9_loss: 0.3912 - val_dense_10_loss: 0.4981 - val_dense_11_loss: 0.5611 - val_dense_12_loss: 0.5631 - val_dense_13_loss: 0.7571 - val_dense_14_loss: 0.5488 - val_dense_15_loss: 0.8084 - val_dense_16_loss: 0.7787 - val_dense_17_loss: 0.6653 - val_dense_18_loss: 0.4661 - val_dense_19_loss: 0.6858 - val_dense_20_loss: 0.5829\n",
      "Epoch 5/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 10.3239 - dense_1_loss: 0.2412 - dense_2_loss: 0.3483 - dense_3_loss: 0.3484 - dense_4_loss: 0.4061 - dense_5_loss: 0.5669 - dense_6_loss: 0.2292 - dense_7_loss: 0.3712 - dense_8_loss: 0.7229 - dense_9_loss: 0.3799 - dense_10_loss: 0.4859 - dense_11_loss: 0.5444 - dense_12_loss: 0.5438 - dense_13_loss: 0.7515 - dense_14_loss: 0.5383 - dense_15_loss: 0.7757 - dense_16_loss: 0.7519 - dense_17_loss: 0.6445 - dense_18_loss: 0.4460 - dense_19_loss: 0.6600 - dense_20_loss: 0.5676 - val_loss: 10.2078 - val_dense_1_loss: 0.2335 - val_dense_2_loss: 0.3465 - val_dense_3_loss: 0.3451 - val_dense_4_loss: 0.3889 - val_dense_5_loss: 0.5705 - val_dense_6_loss: 0.1656 - val_dense_7_loss: 0.3711 - val_dense_8_loss: 0.7256 - val_dense_9_loss: 0.3789 - val_dense_10_loss: 0.4852 - val_dense_11_loss: 0.5460 - val_dense_12_loss: 0.5529 - val_dense_13_loss: 0.7289 - val_dense_14_loss: 0.5341 - val_dense_15_loss: 0.7797 - val_dense_16_loss: 0.7417 - val_dense_17_loss: 0.6518 - val_dense_18_loss: 0.4485 - val_dense_19_loss: 0.6568 - val_dense_20_loss: 0.5566\n",
      "Epoch 6/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 9.8071 - dense_1_loss: 0.2306 - dense_2_loss: 0.3249 - dense_3_loss: 0.3311 - dense_4_loss: 0.3726 - dense_5_loss: 0.5447 - dense_6_loss: 0.1347 - dense_7_loss: 0.3556 - dense_8_loss: 0.6855 - dense_9_loss: 0.3679 - dense_10_loss: 0.4717 - dense_11_loss: 0.5272 - dense_12_loss: 0.5302 - dense_13_loss: 0.7221 - dense_14_loss: 0.5191 - dense_15_loss: 0.7443 - dense_16_loss: 0.7160 - dense_17_loss: 0.6281 - dense_18_loss: 0.4271 - dense_19_loss: 0.6317 - dense_20_loss: 0.5419 - val_loss: 9.8853 - val_dense_1_loss: 0.2280 - val_dense_2_loss: 0.3338 - val_dense_3_loss: 0.3351 - val_dense_4_loss: 0.3762 - val_dense_5_loss: 0.5494 - val_dense_6_loss: 0.1211 - val_dense_7_loss: 0.3569 - val_dense_8_loss: 0.6992 - val_dense_9_loss: 0.3705 - val_dense_10_loss: 0.4774 - val_dense_11_loss: 0.5350 - val_dense_12_loss: 0.5438 - val_dense_13_loss: 0.7052 - val_dense_14_loss: 0.5204 - val_dense_15_loss: 0.7604 - val_dense_16_loss: 0.7181 - val_dense_17_loss: 0.6433 - val_dense_18_loss: 0.4331 - val_dense_19_loss: 0.6379 - val_dense_20_loss: 0.5405\n",
      "Epoch 7/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 9.4605 - dense_1_loss: 0.2225 - dense_2_loss: 0.3112 - dense_3_loss: 0.3175 - dense_4_loss: 0.3618 - dense_5_loss: 0.5207 - dense_6_loss: 0.1138 - dense_7_loss: 0.3405 - dense_8_loss: 0.6582 - dense_9_loss: 0.3579 - dense_10_loss: 0.4603 - dense_11_loss: 0.5122 - dense_12_loss: 0.5182 - dense_13_loss: 0.6962 - dense_14_loss: 0.5025 - dense_15_loss: 0.7195 - dense_16_loss: 0.6886 - dense_17_loss: 0.6147 - dense_18_loss: 0.4113 - dense_19_loss: 0.6103 - dense_20_loss: 0.5229 - val_loss: 9.6591 - val_dense_1_loss: 0.2228 - val_dense_2_loss: 0.3270 - val_dense_3_loss: 0.3266 - val_dense_4_loss: 0.3679 - val_dense_5_loss: 0.5333 - val_dense_6_loss: 0.1115 - val_dense_7_loss: 0.3448 - val_dense_8_loss: 0.6803 - val_dense_9_loss: 0.3627 - val_dense_10_loss: 0.4704 - val_dense_11_loss: 0.5250 - val_dense_12_loss: 0.5353 - val_dense_13_loss: 0.6871 - val_dense_14_loss: 0.5098 - val_dense_15_loss: 0.7457 - val_dense_16_loss: 0.6981 - val_dense_17_loss: 0.6365 - val_dense_18_loss: 0.4216 - val_dense_19_loss: 0.6236 - val_dense_20_loss: 0.5290\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 41s 387us/step - loss: 9.1785 - dense_1_loss: 0.2155 - dense_2_loss: 0.3017 - dense_3_loss: 0.3062 - dense_4_loss: 0.3539 - dense_5_loss: 0.5019 - dense_6_loss: 0.1071 - dense_7_loss: 0.3260 - dense_8_loss: 0.6360 - dense_9_loss: 0.3489 - dense_10_loss: 0.4505 - dense_11_loss: 0.4984 - dense_12_loss: 0.5064 - dense_13_loss: 0.6733 - dense_14_loss: 0.4877 - dense_15_loss: 0.6986 - dense_16_loss: 0.6664 - dense_17_loss: 0.6028 - dense_18_loss: 0.3979 - dense_19_loss: 0.5921 - dense_20_loss: 0.5073 - val_loss: 9.4894 - val_dense_1_loss: 0.2192 - val_dense_2_loss: 0.3243 - val_dense_3_loss: 0.3216 - val_dense_4_loss: 0.3615 - val_dense_5_loss: 0.5219 - val_dense_6_loss: 0.1084 - val_dense_7_loss: 0.3325 - val_dense_8_loss: 0.6660 - val_dense_9_loss: 0.3584 - val_dense_10_loss: 0.4660 - val_dense_11_loss: 0.5166 - val_dense_12_loss: 0.5279 - val_dense_13_loss: 0.6700 - val_dense_14_loss: 0.5005 - val_dense_15_loss: 0.7346 - val_dense_16_loss: 0.6855 - val_dense_17_loss: 0.6318 - val_dense_18_loss: 0.4114 - val_dense_19_loss: 0.6117 - val_dense_20_loss: 0.5197\n",
      "Epoch 9/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 8.9342 - dense_1_loss: 0.2092 - dense_2_loss: 0.2937 - dense_3_loss: 0.2966 - dense_4_loss: 0.3476 - dense_5_loss: 0.4872 - dense_6_loss: 0.1040 - dense_7_loss: 0.3119 - dense_8_loss: 0.6168 - dense_9_loss: 0.3424 - dense_10_loss: 0.4420 - dense_11_loss: 0.4860 - dense_12_loss: 0.4937 - dense_13_loss: 0.6531 - dense_14_loss: 0.4743 - dense_15_loss: 0.6801 - dense_16_loss: 0.6482 - dense_17_loss: 0.5917 - dense_18_loss: 0.3856 - dense_19_loss: 0.5761 - dense_20_loss: 0.4940 - val_loss: 9.3543 - val_dense_1_loss: 0.2159 - val_dense_2_loss: 0.3216 - val_dense_3_loss: 0.3174 - val_dense_4_loss: 0.3566 - val_dense_5_loss: 0.5135 - val_dense_6_loss: 0.1062 - val_dense_7_loss: 0.3229 - val_dense_8_loss: 0.6549 - val_dense_9_loss: 0.3547 - val_dense_10_loss: 0.4624 - val_dense_11_loss: 0.5104 - val_dense_12_loss: 0.5195 - val_dense_13_loss: 0.6575 - val_dense_14_loss: 0.4939 - val_dense_15_loss: 0.7261 - val_dense_16_loss: 0.6754 - val_dense_17_loss: 0.6274 - val_dense_18_loss: 0.4031 - val_dense_19_loss: 0.6015 - val_dense_20_loss: 0.5134\n",
      "Epoch 10/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 8.7155 - dense_1_loss: 0.2032 - dense_2_loss: 0.2868 - dense_3_loss: 0.2878 - dense_4_loss: 0.3422 - dense_5_loss: 0.4746 - dense_6_loss: 0.1019 - dense_7_loss: 0.3002 - dense_8_loss: 0.5998 - dense_9_loss: 0.3367 - dense_10_loss: 0.4344 - dense_11_loss: 0.4746 - dense_12_loss: 0.4812 - dense_13_loss: 0.6343 - dense_14_loss: 0.4624 - dense_15_loss: 0.6632 - dense_16_loss: 0.6319 - dense_17_loss: 0.5808 - dense_18_loss: 0.3750 - dense_19_loss: 0.5620 - dense_20_loss: 0.4825 - val_loss: 9.2475 - val_dense_1_loss: 0.2138 - val_dense_2_loss: 0.3202 - val_dense_3_loss: 0.3146 - val_dense_4_loss: 0.3529 - val_dense_5_loss: 0.5074 - val_dense_6_loss: 0.1048 - val_dense_7_loss: 0.3139 - val_dense_8_loss: 0.6467 - val_dense_9_loss: 0.3522 - val_dense_10_loss: 0.4598 - val_dense_11_loss: 0.5058 - val_dense_12_loss: 0.5102 - val_dense_13_loss: 0.6468 - val_dense_14_loss: 0.4882 - val_dense_15_loss: 0.7196 - val_dense_16_loss: 0.6678 - val_dense_17_loss: 0.6244 - val_dense_18_loss: 0.3968 - val_dense_19_loss: 0.5938 - val_dense_20_loss: 0.5078\n",
      "Epoch 11/300\n",
      "105000/105000 [==============================] - 41s 386us/step - loss: 8.5139 - dense_1_loss: 0.1975 - dense_2_loss: 0.2802 - dense_3_loss: 0.2802 - dense_4_loss: 0.3371 - dense_5_loss: 0.4631 - dense_6_loss: 0.1001 - dense_7_loss: 0.2905 - dense_8_loss: 0.5844 - dense_9_loss: 0.3316 - dense_10_loss: 0.4275 - dense_11_loss: 0.4643 - dense_12_loss: 0.4677 - dense_13_loss: 0.6163 - dense_14_loss: 0.4517 - dense_15_loss: 0.6477 - dense_16_loss: 0.6168 - dense_17_loss: 0.5703 - dense_18_loss: 0.3655 - dense_19_loss: 0.5495 - dense_20_loss: 0.4720 - val_loss: 9.1632 - val_dense_1_loss: 0.2114 - val_dense_2_loss: 0.3198 - val_dense_3_loss: 0.3127 - val_dense_4_loss: 0.3504 - val_dense_5_loss: 0.5037 - val_dense_6_loss: 0.1035 - val_dense_7_loss: 0.3075 - val_dense_8_loss: 0.6397 - val_dense_9_loss: 0.3500 - val_dense_10_loss: 0.4576 - val_dense_11_loss: 0.5009 - val_dense_12_loss: 0.5015 - val_dense_13_loss: 0.6359 - val_dense_14_loss: 0.4838 - val_dense_15_loss: 0.7151 - val_dense_16_loss: 0.6627 - val_dense_17_loss: 0.6227 - val_dense_18_loss: 0.3916 - val_dense_19_loss: 0.5884 - val_dense_20_loss: 0.5042\n",
      "Epoch 12/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 8.3249 - dense_1_loss: 0.1923 - dense_2_loss: 0.2742 - dense_3_loss: 0.2729 - dense_4_loss: 0.3322 - dense_5_loss: 0.4526 - dense_6_loss: 0.0984 - dense_7_loss: 0.2823 - dense_8_loss: 0.5700 - dense_9_loss: 0.3270 - dense_10_loss: 0.4208 - dense_11_loss: 0.4544 - dense_12_loss: 0.4543 - dense_13_loss: 0.5989 - dense_14_loss: 0.4418 - dense_15_loss: 0.6332 - dense_16_loss: 0.6028 - dense_17_loss: 0.5600 - dense_18_loss: 0.3566 - dense_19_loss: 0.5380 - dense_20_loss: 0.4623 - val_loss: 9.0904 - val_dense_1_loss: 0.2098 - val_dense_2_loss: 0.3193 - val_dense_3_loss: 0.3112 - val_dense_4_loss: 0.3468 - val_dense_5_loss: 0.4998 - val_dense_6_loss: 0.1021 - val_dense_7_loss: 0.3022 - val_dense_8_loss: 0.6356 - val_dense_9_loss: 0.3488 - val_dense_10_loss: 0.4562 - val_dense_11_loss: 0.4975 - val_dense_12_loss: 0.4920 - val_dense_13_loss: 0.6272 - val_dense_14_loss: 0.4792 - val_dense_15_loss: 0.7103 - val_dense_16_loss: 0.6580 - val_dense_17_loss: 0.6226 - val_dense_18_loss: 0.3879 - val_dense_19_loss: 0.5836 - val_dense_20_loss: 0.5003\n",
      "Epoch 13/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 8.1457 - dense_1_loss: 0.1873 - dense_2_loss: 0.2684 - dense_3_loss: 0.2662 - dense_4_loss: 0.3273 - dense_5_loss: 0.4426 - dense_6_loss: 0.0966 - dense_7_loss: 0.2754 - dense_8_loss: 0.5568 - dense_9_loss: 0.3227 - dense_10_loss: 0.4142 - dense_11_loss: 0.4452 - dense_12_loss: 0.4414 - dense_13_loss: 0.5824 - dense_14_loss: 0.4320 - dense_15_loss: 0.6197 - dense_16_loss: 0.5889 - dense_17_loss: 0.5498 - dense_18_loss: 0.3486 - dense_19_loss: 0.5272 - dense_20_loss: 0.4528 - val_loss: 9.0305 - val_dense_1_loss: 0.2077 - val_dense_2_loss: 0.3192 - val_dense_3_loss: 0.3099 - val_dense_4_loss: 0.3443 - val_dense_5_loss: 0.4969 - val_dense_6_loss: 0.1008 - val_dense_7_loss: 0.2976 - val_dense_8_loss: 0.6313 - val_dense_9_loss: 0.3476 - val_dense_10_loss: 0.4552 - val_dense_11_loss: 0.4959 - val_dense_12_loss: 0.4847 - val_dense_13_loss: 0.6183 - val_dense_14_loss: 0.4760 - val_dense_15_loss: 0.7080 - val_dense_16_loss: 0.6545 - val_dense_17_loss: 0.6205 - val_dense_18_loss: 0.3845 - val_dense_19_loss: 0.5796 - val_dense_20_loss: 0.4977\n",
      "Epoch 14/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.9747 - dense_1_loss: 0.1829 - dense_2_loss: 0.2629 - dense_3_loss: 0.2599 - dense_4_loss: 0.3225 - dense_5_loss: 0.4333 - dense_6_loss: 0.0950 - dense_7_loss: 0.2690 - dense_8_loss: 0.5443 - dense_9_loss: 0.3186 - dense_10_loss: 0.4079 - dense_11_loss: 0.4360 - dense_12_loss: 0.4291 - dense_13_loss: 0.5672 - dense_14_loss: 0.4221 - dense_15_loss: 0.6065 - dense_16_loss: 0.5758 - dense_17_loss: 0.5398 - dense_18_loss: 0.3409 - dense_19_loss: 0.5170 - dense_20_loss: 0.4440 - val_loss: 8.9913 - val_dense_1_loss: 0.2069 - val_dense_2_loss: 0.3197 - val_dense_3_loss: 0.3094 - val_dense_4_loss: 0.3418 - val_dense_5_loss: 0.4945 - val_dense_6_loss: 0.0996 - val_dense_7_loss: 0.2943 - val_dense_8_loss: 0.6283 - val_dense_9_loss: 0.3474 - val_dense_10_loss: 0.4545 - val_dense_11_loss: 0.4931 - val_dense_12_loss: 0.4787 - val_dense_13_loss: 0.6127 - val_dense_14_loss: 0.4733 - val_dense_15_loss: 0.7075 - val_dense_16_loss: 0.6523 - val_dense_17_loss: 0.6211 - val_dense_18_loss: 0.3832 - val_dense_19_loss: 0.5776 - val_dense_20_loss: 0.4956\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.8105 - dense_1_loss: 0.1789 - dense_2_loss: 0.2575 - dense_3_loss: 0.2537 - dense_4_loss: 0.3180 - dense_5_loss: 0.4237 - dense_6_loss: 0.0933 - dense_7_loss: 0.2633 - dense_8_loss: 0.5326 - dense_9_loss: 0.3143 - dense_10_loss: 0.4016 - dense_11_loss: 0.4270 - dense_12_loss: 0.4178 - dense_13_loss: 0.5525 - dense_14_loss: 0.4126 - dense_15_loss: 0.5944 - dense_16_loss: 0.5629 - dense_17_loss: 0.5298 - dense_18_loss: 0.3337 - dense_19_loss: 0.5073 - dense_20_loss: 0.4356 - val_loss: 8.9594 - val_dense_1_loss: 0.2066 - val_dense_2_loss: 0.3209 - val_dense_3_loss: 0.3094 - val_dense_4_loss: 0.3401 - val_dense_5_loss: 0.4934 - val_dense_6_loss: 0.0987 - val_dense_7_loss: 0.2913 - val_dense_8_loss: 0.6260 - val_dense_9_loss: 0.3465 - val_dense_10_loss: 0.4546 - val_dense_11_loss: 0.4910 - val_dense_12_loss: 0.4742 - val_dense_13_loss: 0.6064 - val_dense_14_loss: 0.4713 - val_dense_15_loss: 0.7053 - val_dense_16_loss: 0.6511 - val_dense_17_loss: 0.6214 - val_dense_18_loss: 0.3812 - val_dense_19_loss: 0.5755 - val_dense_20_loss: 0.4948\n",
      "Epoch 16/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.6516 - dense_1_loss: 0.1751 - dense_2_loss: 0.2520 - dense_3_loss: 0.2480 - dense_4_loss: 0.3134 - dense_5_loss: 0.4147 - dense_6_loss: 0.0917 - dense_7_loss: 0.2580 - dense_8_loss: 0.5212 - dense_9_loss: 0.3102 - dense_10_loss: 0.3954 - dense_11_loss: 0.4180 - dense_12_loss: 0.4075 - dense_13_loss: 0.5387 - dense_14_loss: 0.4033 - dense_15_loss: 0.5824 - dense_16_loss: 0.5501 - dense_17_loss: 0.5203 - dense_18_loss: 0.3266 - dense_19_loss: 0.4975 - dense_20_loss: 0.4275 - val_loss: 8.9380 - val_dense_1_loss: 0.2063 - val_dense_2_loss: 0.3217 - val_dense_3_loss: 0.3091 - val_dense_4_loss: 0.3381 - val_dense_5_loss: 0.4925 - val_dense_6_loss: 0.0977 - val_dense_7_loss: 0.2890 - val_dense_8_loss: 0.6253 - val_dense_9_loss: 0.3462 - val_dense_10_loss: 0.4537 - val_dense_11_loss: 0.4902 - val_dense_12_loss: 0.4684 - val_dense_13_loss: 0.6027 - val_dense_14_loss: 0.4687 - val_dense_15_loss: 0.7053 - val_dense_16_loss: 0.6496 - val_dense_17_loss: 0.6238 - val_dense_18_loss: 0.3803 - val_dense_19_loss: 0.5748 - val_dense_20_loss: 0.4946\n",
      "Epoch 17/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.4967 - dense_1_loss: 0.1714 - dense_2_loss: 0.2469 - dense_3_loss: 0.2421 - dense_4_loss: 0.3092 - dense_5_loss: 0.4057 - dense_6_loss: 0.0901 - dense_7_loss: 0.2532 - dense_8_loss: 0.5102 - dense_9_loss: 0.3062 - dense_10_loss: 0.3892 - dense_11_loss: 0.4091 - dense_12_loss: 0.3977 - dense_13_loss: 0.5257 - dense_14_loss: 0.3939 - dense_15_loss: 0.5709 - dense_16_loss: 0.5371 - dense_17_loss: 0.5106 - dense_18_loss: 0.3201 - dense_19_loss: 0.4879 - dense_20_loss: 0.4196 - val_loss: 8.9221 - val_dense_1_loss: 0.2060 - val_dense_2_loss: 0.3226 - val_dense_3_loss: 0.3093 - val_dense_4_loss: 0.3364 - val_dense_5_loss: 0.4914 - val_dense_6_loss: 0.0965 - val_dense_7_loss: 0.2872 - val_dense_8_loss: 0.6233 - val_dense_9_loss: 0.3457 - val_dense_10_loss: 0.4538 - val_dense_11_loss: 0.4896 - val_dense_12_loss: 0.4657 - val_dense_13_loss: 0.5991 - val_dense_14_loss: 0.4672 - val_dense_15_loss: 0.7048 - val_dense_16_loss: 0.6512 - val_dense_17_loss: 0.6251 - val_dense_18_loss: 0.3792 - val_dense_19_loss: 0.5738 - val_dense_20_loss: 0.4944\n",
      "Epoch 18/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.3453 - dense_1_loss: 0.1680 - dense_2_loss: 0.2415 - dense_3_loss: 0.2366 - dense_4_loss: 0.3050 - dense_5_loss: 0.3970 - dense_6_loss: 0.0887 - dense_7_loss: 0.2486 - dense_8_loss: 0.4994 - dense_9_loss: 0.3022 - dense_10_loss: 0.3830 - dense_11_loss: 0.4008 - dense_12_loss: 0.3882 - dense_13_loss: 0.5131 - dense_14_loss: 0.3846 - dense_15_loss: 0.5597 - dense_16_loss: 0.5242 - dense_17_loss: 0.5015 - dense_18_loss: 0.3136 - dense_19_loss: 0.4779 - dense_20_loss: 0.4117 - val_loss: 8.9159 - val_dense_1_loss: 0.2062 - val_dense_2_loss: 0.3237 - val_dense_3_loss: 0.3098 - val_dense_4_loss: 0.3347 - val_dense_5_loss: 0.4905 - val_dense_6_loss: 0.0958 - val_dense_7_loss: 0.2856 - val_dense_8_loss: 0.6236 - val_dense_9_loss: 0.3457 - val_dense_10_loss: 0.4536 - val_dense_11_loss: 0.4897 - val_dense_12_loss: 0.4629 - val_dense_13_loss: 0.5960 - val_dense_14_loss: 0.4673 - val_dense_15_loss: 0.7059 - val_dense_16_loss: 0.6508 - val_dense_17_loss: 0.6266 - val_dense_18_loss: 0.3791 - val_dense_19_loss: 0.5740 - val_dense_20_loss: 0.4943\n",
      "Epoch 19/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.1962 - dense_1_loss: 0.1646 - dense_2_loss: 0.2363 - dense_3_loss: 0.2310 - dense_4_loss: 0.3009 - dense_5_loss: 0.3883 - dense_6_loss: 0.0873 - dense_7_loss: 0.2443 - dense_8_loss: 0.4892 - dense_9_loss: 0.2981 - dense_10_loss: 0.3766 - dense_11_loss: 0.3925 - dense_12_loss: 0.3792 - dense_13_loss: 0.5004 - dense_14_loss: 0.3758 - dense_15_loss: 0.5487 - dense_16_loss: 0.5115 - dense_17_loss: 0.4924 - dense_18_loss: 0.3072 - dense_19_loss: 0.4678 - dense_20_loss: 0.4042 - val_loss: 8.9190 - val_dense_1_loss: 0.2054 - val_dense_2_loss: 0.3251 - val_dense_3_loss: 0.3105 - val_dense_4_loss: 0.3335 - val_dense_5_loss: 0.4905 - val_dense_6_loss: 0.0954 - val_dense_7_loss: 0.2847 - val_dense_8_loss: 0.6234 - val_dense_9_loss: 0.3458 - val_dense_10_loss: 0.4554 - val_dense_11_loss: 0.4905 - val_dense_12_loss: 0.4607 - val_dense_13_loss: 0.5929 - val_dense_14_loss: 0.4660 - val_dense_15_loss: 0.7083 - val_dense_16_loss: 0.6518 - val_dense_17_loss: 0.6301 - val_dense_18_loss: 0.3796 - val_dense_19_loss: 0.5744 - val_dense_20_loss: 0.4947\n",
      "Epoch 20/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 7.0502 - dense_1_loss: 0.1613 - dense_2_loss: 0.2309 - dense_3_loss: 0.2258 - dense_4_loss: 0.2969 - dense_5_loss: 0.3797 - dense_6_loss: 0.0860 - dense_7_loss: 0.2404 - dense_8_loss: 0.4788 - dense_9_loss: 0.2942 - dense_10_loss: 0.3704 - dense_11_loss: 0.3843 - dense_12_loss: 0.3703 - dense_13_loss: 0.4884 - dense_14_loss: 0.3670 - dense_15_loss: 0.5382 - dense_16_loss: 0.4985 - dense_17_loss: 0.4836 - dense_18_loss: 0.3009 - dense_19_loss: 0.4578 - dense_20_loss: 0.3967 - val_loss: 8.9324 - val_dense_1_loss: 0.2071 - val_dense_2_loss: 0.3269 - val_dense_3_loss: 0.3109 - val_dense_4_loss: 0.3325 - val_dense_5_loss: 0.4907 - val_dense_6_loss: 0.0947 - val_dense_7_loss: 0.2834 - val_dense_8_loss: 0.6249 - val_dense_9_loss: 0.3465 - val_dense_10_loss: 0.4552 - val_dense_11_loss: 0.4914 - val_dense_12_loss: 0.4609 - val_dense_13_loss: 0.5925 - val_dense_14_loss: 0.4669 - val_dense_15_loss: 0.7109 - val_dense_16_loss: 0.6540 - val_dense_17_loss: 0.6326 - val_dense_18_loss: 0.3792 - val_dense_19_loss: 0.5755 - val_dense_20_loss: 0.4957\n",
      "Epoch 21/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 6.9064 - dense_1_loss: 0.1582 - dense_2_loss: 0.2258 - dense_3_loss: 0.2205 - dense_4_loss: 0.2928 - dense_5_loss: 0.3711 - dense_6_loss: 0.0848 - dense_7_loss: 0.2366 - dense_8_loss: 0.4690 - dense_9_loss: 0.2900 - dense_10_loss: 0.3642 - dense_11_loss: 0.3763 - dense_12_loss: 0.3619 - dense_13_loss: 0.4766 - dense_14_loss: 0.3583 - dense_15_loss: 0.5278 - dense_16_loss: 0.4858 - dense_17_loss: 0.4750 - dense_18_loss: 0.2950 - dense_19_loss: 0.4476 - dense_20_loss: 0.3892 - val_loss: 8.9433 - val_dense_1_loss: 0.2062 - val_dense_2_loss: 0.3289 - val_dense_3_loss: 0.3124 - val_dense_4_loss: 0.3315 - val_dense_5_loss: 0.4916 - val_dense_6_loss: 0.0946 - val_dense_7_loss: 0.2830 - val_dense_8_loss: 0.6256 - val_dense_9_loss: 0.3474 - val_dense_10_loss: 0.4561 - val_dense_11_loss: 0.4921 - val_dense_12_loss: 0.4596 - val_dense_13_loss: 0.5905 - val_dense_14_loss: 0.4663 - val_dense_15_loss: 0.7120 - val_dense_16_loss: 0.6556 - val_dense_17_loss: 0.6361 - val_dense_18_loss: 0.3800 - val_dense_19_loss: 0.5774 - val_dense_20_loss: 0.4964\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 22/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 41s 387us/step - loss: 6.7316 - dense_1_loss: 0.1542 - dense_2_loss: 0.2176 - dense_3_loss: 0.2137 - dense_4_loss: 0.2888 - dense_5_loss: 0.3616 - dense_6_loss: 0.0836 - dense_7_loss: 0.2323 - dense_8_loss: 0.4565 - dense_9_loss: 0.2853 - dense_10_loss: 0.3562 - dense_11_loss: 0.3668 - dense_12_loss: 0.3528 - dense_13_loss: 0.4646 - dense_14_loss: 0.3484 - dense_15_loss: 0.5132 - dense_16_loss: 0.4700 - dense_17_loss: 0.4627 - dense_18_loss: 0.2876 - dense_19_loss: 0.4360 - dense_20_loss: 0.3798 - val_loss: 8.9413 - val_dense_1_loss: 0.2067 - val_dense_2_loss: 0.3284 - val_dense_3_loss: 0.3120 - val_dense_4_loss: 0.3312 - val_dense_5_loss: 0.4912 - val_dense_6_loss: 0.0943 - val_dense_7_loss: 0.2825 - val_dense_8_loss: 0.6252 - val_dense_9_loss: 0.3469 - val_dense_10_loss: 0.4562 - val_dense_11_loss: 0.4924 - val_dense_12_loss: 0.4590 - val_dense_13_loss: 0.5903 - val_dense_14_loss: 0.4665 - val_dense_15_loss: 0.7127 - val_dense_16_loss: 0.6559 - val_dense_17_loss: 0.6367 - val_dense_18_loss: 0.3798 - val_dense_19_loss: 0.5769 - val_dense_20_loss: 0.4965\n",
      "Epoch 23/300\n",
      "105000/105000 [==============================] - 41s 387us/step - loss: 6.7142 - dense_1_loss: 0.1538 - dense_2_loss: 0.2169 - dense_3_loss: 0.2131 - dense_4_loss: 0.2884 - dense_5_loss: 0.3607 - dense_6_loss: 0.0834 - dense_7_loss: 0.2318 - dense_8_loss: 0.4554 - dense_9_loss: 0.2847 - dense_10_loss: 0.3554 - dense_11_loss: 0.3657 - dense_12_loss: 0.3519 - dense_13_loss: 0.4633 - dense_14_loss: 0.3475 - dense_15_loss: 0.5119 - dense_16_loss: 0.4684 - dense_17_loss: 0.4615 - dense_18_loss: 0.2869 - dense_19_loss: 0.4346 - dense_20_loss: 0.3789 - val_loss: 8.9431 - val_dense_1_loss: 0.2065 - val_dense_2_loss: 0.3287 - val_dense_3_loss: 0.3121 - val_dense_4_loss: 0.3311 - val_dense_5_loss: 0.4912 - val_dense_6_loss: 0.0943 - val_dense_7_loss: 0.2825 - val_dense_8_loss: 0.6253 - val_dense_9_loss: 0.3469 - val_dense_10_loss: 0.4563 - val_dense_11_loss: 0.4925 - val_dense_12_loss: 0.4588 - val_dense_13_loss: 0.5902 - val_dense_14_loss: 0.4665 - val_dense_15_loss: 0.7129 - val_dense_16_loss: 0.6563 - val_dense_17_loss: 0.6373 - val_dense_18_loss: 0.3801 - val_dense_19_loss: 0.5772 - val_dense_20_loss: 0.4966\n",
      "Epoch 24/300\n",
      "100416/105000 [===========================>..] - ETA: 1s - loss: 6.6949 - dense_1_loss: 0.1528 - dense_2_loss: 0.2151 - dense_3_loss: 0.2126 - dense_4_loss: 0.2878 - dense_5_loss: 0.3593 - dense_6_loss: 0.0827 - dense_7_loss: 0.2309 - dense_8_loss: 0.4541 - dense_9_loss: 0.2841 - dense_10_loss: 0.3544 - dense_11_loss: 0.3650 - dense_12_loss: 0.3507 - dense_13_loss: 0.4627 - dense_14_loss: 0.3466 - dense_15_loss: 0.5112 - dense_16_loss: 0.4660 - dense_17_loss: 0.4600 - dense_18_loss: 0.2870 - dense_19_loss: 0.4337 - dense_20_loss: 0.3782"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_outputs, \n",
    "          validation_data = (val_x, val_outputs),\n",
    "          model_file = MODEL_FILE\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._model.load_weights(MODEL_FILE)\n",
    "val_probs = model.predict(val_x)\n",
    "test_probs = model.predict(test_x)\n",
    "\n",
    "val_preds = list(map(lambda x: np.argmax(x, axis = -1), val_probs))\n",
    "# val_preds = np.argmax(val_probs, axis = 1)\n",
    "# test_preds = list(map(lambda x: np.argmax(x, axis = -1), test_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f1s = 0\n",
    "for i, (vy, vp) in enumerate(zip(val_ys, val_preds)):\n",
    "    f1 = f1_score(vy, vp, average='macro')\n",
    "    print(\"The %sth f1: %s\" % (i, f1))\n",
    "    f1s += f1\n",
    "    \n",
    "print(\"The average f1 of val is %s\" % (f1s / len(y_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
