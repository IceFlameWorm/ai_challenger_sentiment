{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(4444)\n",
    "import pickle\n",
    "import numpy as np\n",
    "np.random.seed(5555)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(6666)\n",
    "import pandas as pd\n",
    "from utils.dataset import DataSet, LABELS\n",
    "from models.linxi import train_CNN\n",
    "from env import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SEQS_PADDED_PKL = os.path.join(CACHES_PATH, 'train_seqs_padded.pkl')\n",
    "VAL_SEQS_PADDED_PKL = os.path.join(CACHES_PATH, 'val_seqs_padded.pkl')\n",
    "TEST_SEQS_PADDED_PKL = os.path.join(CACHES_PATH, 'test_seqs_padded.pkl')\n",
    "\n",
    "RESULT_CSV = os.path.join(RESULTS_PATH, 'baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = DataSet()\n",
    "train, val, test = raw_dataset.train, raw_dataset.val, raw_dataset.test\n",
    "\n",
    "with open(TRAIN_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    train_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(VAL_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    val_seqs_padded = pickle.load(f)\n",
    "    \n",
    "with open(TEST_SEQS_PADDED_PKL, 'rb') as f:\n",
    "    test_seqs_padded = pickle.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_seq = pd.merge(train, train_seqs_padded, on='id')\n",
    "val_with_seq = pd.merge(val, val_seqs_padded, on='id')\n",
    "test_with_seq = pd.merge(test, test_seqs_padded, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 248us/step - loss: 0.5131 - acc: 0.8323 - val_loss: 0.2426 - val_acc: 0.9331\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2358 - acc: 0.9350 - val_loss: 0.2256 - val_acc: 0.9375\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 235us/step - loss: 0.2128 - acc: 0.9398 - val_loss: 0.2219 - val_acc: 0.9394\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.1923 - acc: 0.9442 - val_loss: 0.2233 - val_acc: 0.9396\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.1682 - acc: 0.9498 - val_loss: 0.2264 - val_acc: 0.9387\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1403 - acc: 0.9563 - val_loss: 0.2293 - val_acc: 0.9397\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.1118 - acc: 0.9657 - val_loss: 0.2322 - val_acc: 0.9397\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.1054 - acc: 0.9678 - val_loss: 0.2360 - val_acc: 0.9391\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.0994 - acc: 0.9697 - val_loss: 0.2390 - val_acc: 0.9385\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 0th grain: f1_score - 0.5239356264879911, acc - 0.9397333333333333\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "   320/105000 [..............................] - ETA: 57s - loss: 1.3346 - acc: 0.7344 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.4068 - acc: 0.8535 - val_loss: 0.3367 - val_acc: 0.8781\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2889 - acc: 0.8951 - val_loss: 0.3247 - val_acc: 0.8821\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.2464 - acc: 0.9116 - val_loss: 0.3293 - val_acc: 0.8809\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 234us/step - loss: 0.2063 - acc: 0.9270 - val_loss: 0.3430 - val_acc: 0.8800\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 234us/step - loss: 0.1656 - acc: 0.9445 - val_loss: 0.3641 - val_acc: 0.8761\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.1220 - acc: 0.9642 - val_loss: 0.3743 - val_acc: 0.8752\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.1127 - acc: 0.9673 - val_loss: 0.3834 - val_acc: 0.8738\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1042 - acc: 0.9704 - val_loss: 0.3946 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 1th grain: f1_score - 0.40497252271296214, acc - 0.8820666666666667\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.3756 - acc: 0.8774 - val_loss: 0.3113 - val_acc: 0.9031\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.2705 - acc: 0.9123 - val_loss: 0.3012 - val_acc: 0.9067\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2308 - acc: 0.9234 - val_loss: 0.2998 - val_acc: 0.9072\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.1936 - acc: 0.9352 - val_loss: 0.3101 - val_acc: 0.9067\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.1570 - acc: 0.9485 - val_loss: 0.3241 - val_acc: 0.9048\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.1227 - acc: 0.9611 - val_loss: 0.3474 - val_acc: 0.9011\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.0896 - acc: 0.9745 - val_loss: 0.3581 - val_acc: 0.9005\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.0831 - acc: 0.9768 - val_loss: 0.3678 - val_acc: 0.8999\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.0769 - acc: 0.9791 - val_loss: 0.3742 - val_acc: 0.8987\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 2th grain: f1_score - 0.612868189462613, acc - 0.9072\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.3983 - acc: 0.8873 - val_loss: 0.3202 - val_acc: 0.8989\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 235us/step - loss: 0.2887 - acc: 0.9072 - val_loss: 0.3041 - val_acc: 0.9029\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.2498 - acc: 0.9177 - val_loss: 0.3026 - val_acc: 0.9043\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2137 - acc: 0.9283 - val_loss: 0.3094 - val_acc: 0.9047\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1779 - acc: 0.9403 - val_loss: 0.3249 - val_acc: 0.9027\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.1426 - acc: 0.9533 - val_loss: 0.3485 - val_acc: 0.8998\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1074 - acc: 0.9678 - val_loss: 0.3597 - val_acc: 0.8998\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1001 - acc: 0.9704 - val_loss: 0.3696 - val_acc: 0.8990\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.0932 - acc: 0.9732 - val_loss: 0.3781 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 3th grain: f1_score - 0.5506936289072112, acc - 0.9047333333333333\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.6633 - acc: 0.7513 - val_loss: 0.5396 - val_acc: 0.7955\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.4638 - acc: 0.8260 - val_loss: 0.5042 - val_acc: 0.8115\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.3980 - acc: 0.8536 - val_loss: 0.4989 - val_acc: 0.8145\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.3430 - acc: 0.8763 - val_loss: 0.5054 - val_acc: 0.8133\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2911 - acc: 0.8984 - val_loss: 0.5154 - val_acc: 0.8157\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.2424 - acc: 0.9197 - val_loss: 0.5388 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.1899 - acc: 0.9444 - val_loss: 0.5481 - val_acc: 0.8107\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.1795 - acc: 0.9485 - val_loss: 0.5545 - val_acc: 0.8077\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.1696 - acc: 0.9525 - val_loss: 0.5646 - val_acc: 0.8090\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 4th grain: f1_score - 0.7117651458401676, acc - 0.8156666666666667\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.2342 - acc: 0.9488 - val_loss: 0.1145 - val_acc: 0.9682\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.0902 - acc: 0.9723 - val_loss: 0.1006 - val_acc: 0.9705\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.0694 - acc: 0.9786 - val_loss: 0.0975 - val_acc: 0.9709\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.0523 - acc: 0.9838 - val_loss: 0.0989 - val_acc: 0.9711\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.0372 - acc: 0.9890 - val_loss: 0.1069 - val_acc: 0.9698\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.0249 - acc: 0.9938 - val_loss: 0.1089 - val_acc: 0.9706\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.0154 - acc: 0.9970 - val_loss: 0.1158 - val_acc: 0.9697\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.0137 - acc: 0.9975 - val_loss: 0.1174 - val_acc: 0.9694\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.0121 - acc: 0.9980 - val_loss: 0.1227 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 5th grain: f1_score - 0.6417282220018753, acc - 0.9710666666666666\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.3596 - acc: 0.8964 - val_loss: 0.2898 - val_acc: 0.9130\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2219 - acc: 0.9291 - val_loss: 0.2720 - val_acc: 0.9183\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.1716 - acc: 0.9446 - val_loss: 0.2706 - val_acc: 0.9191\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1305 - acc: 0.9581 - val_loss: 0.2822 - val_acc: 0.9185\n",
      "Epoch 5/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.0951 - acc: 0.9712 - val_loss: 0.3017 - val_acc: 0.9179\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.0660 - acc: 0.9821 - val_loss: 0.3230 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.0420 - acc: 0.9910 - val_loss: 0.3349 - val_acc: 0.9165\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.0377 - acc: 0.9921 - val_loss: 0.3442 - val_acc: 0.9156\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.0336 - acc: 0.9935 - val_loss: 0.3516 - val_acc: 0.9157\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 6th grain: f1_score - 0.6379514927788742, acc - 0.9190666666666667\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.8914 - acc: 0.6620 - val_loss: 0.7435 - val_acc: 0.7189\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.6350 - acc: 0.7577 - val_loss: 0.6924 - val_acc: 0.7393\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.5399 - acc: 0.7944 - val_loss: 0.6764 - val_acc: 0.7421\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.4608 - acc: 0.8264 - val_loss: 0.6740 - val_acc: 0.7475\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.3869 - acc: 0.8584 - val_loss: 0.6885 - val_acc: 0.7462\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 243us/step - loss: 0.3178 - acc: 0.8889 - val_loss: 0.7150 - val_acc: 0.7443\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2533 - acc: 0.9186 - val_loss: 0.7542 - val_acc: 0.7427\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1897 - acc: 0.9485 - val_loss: 0.7670 - val_acc: 0.7427\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.1771 - acc: 0.9528 - val_loss: 0.7819 - val_acc: 0.7420\n",
      "Epoch 10/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.1649 - acc: 0.9574 - val_loss: 0.7961 - val_acc: 0.7418\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 7th grain: f1_score - 0.6924958257313685, acc - 0.7474666666666666\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.4707 - acc: 0.8411 - val_loss: 0.4046 - val_acc: 0.8658\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.3310 - acc: 0.8840 - val_loss: 0.3939 - val_acc: 0.8719\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2725 - acc: 0.9054 - val_loss: 0.3981 - val_acc: 0.8725\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.2177 - acc: 0.9267 - val_loss: 0.4076 - val_acc: 0.8667\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.1656 - acc: 0.9479 - val_loss: 0.4393 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 237us/step - loss: 0.1170 - acc: 0.9678 - val_loss: 0.4399 - val_acc: 0.8643\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1075 - acc: 0.9709 - val_loss: 0.4580 - val_acc: 0.8628\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.0985 - acc: 0.9742 - val_loss: 0.4601 - val_acc: 0.8633\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 8th grain: f1_score - 0.6320237658792794, acc - 0.8724666666666666\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.6267 - acc: 0.7668 - val_loss: 0.5118 - val_acc: 0.8071\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 26s 245us/step - loss: 0.4408 - acc: 0.8330 - val_loss: 0.4855 - val_acc: 0.8244\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.3721 - acc: 0.8603 - val_loss: 0.4795 - val_acc: 0.8230\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.3134 - acc: 0.8852 - val_loss: 0.4841 - val_acc: 0.8229\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.2570 - acc: 0.9107 - val_loss: 0.5001 - val_acc: 0.8197\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2039 - acc: 0.9345 - val_loss: 0.5229 - val_acc: 0.8147\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1520 - acc: 0.9585 - val_loss: 0.5310 - val_acc: 0.8147\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.1417 - acc: 0.9623 - val_loss: 0.5391 - val_acc: 0.8153\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1316 - acc: 0.9662 - val_loss: 0.5515 - val_acc: 0.8143\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 9th grain: f1_score - 0.590760787418048, acc - 0.8244\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.6675 - acc: 0.7589 - val_loss: 0.5234 - val_acc: 0.8144\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.4518 - acc: 0.8383 - val_loss: 0.4898 - val_acc: 0.8242\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.3716 - acc: 0.8692 - val_loss: 0.4818 - val_acc: 0.8291\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.3049 - acc: 0.8954 - val_loss: 0.4880 - val_acc: 0.8285\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2433 - acc: 0.9201 - val_loss: 0.5062 - val_acc: 0.8242\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1872 - acc: 0.9429 - val_loss: 0.5311 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 236us/step - loss: 0.1341 - acc: 0.9653 - val_loss: 0.5416 - val_acc: 0.8211\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.1240 - acc: 0.9687 - val_loss: 0.5509 - val_acc: 0.8195\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.1140 - acc: 0.9724 - val_loss: 0.5610 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 10th grain: f1_score - 0.614425835543109, acc - 0.8291333333333334\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 247us/step - loss: 0.4957 - acc: 0.8216 - val_loss: 0.4778 - val_acc: 0.8228\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.3573 - acc: 0.8731 - val_loss: 0.4570 - val_acc: 0.8330\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 243us/step - loss: 0.2844 - acc: 0.9032 - val_loss: 0.4610 - val_acc: 0.8333\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.2199 - acc: 0.9301 - val_loss: 0.4737 - val_acc: 0.8320\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1618 - acc: 0.9540 - val_loss: 0.5019 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1110 - acc: 0.9738 - val_loss: 0.5077 - val_acc: 0.8282\n",
      "Epoch 7/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105000/105000 [==============================] - 25s 243us/step - loss: 0.1013 - acc: 0.9771 - val_loss: 0.5173 - val_acc: 0.8287\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.0919 - acc: 0.9799 - val_loss: 0.5263 - val_acc: 0.8277\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 11th grain: f1_score - 0.6451429332003532, acc - 0.8332666666666667\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.5706 - acc: 0.8009 - val_loss: 0.5814 - val_acc: 0.7781\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.3903 - acc: 0.8635 - val_loss: 0.5723 - val_acc: 0.7850\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.3070 - acc: 0.8982 - val_loss: 0.5816 - val_acc: 0.7873\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.2362 - acc: 0.9271 - val_loss: 0.6074 - val_acc: 0.7847\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 243us/step - loss: 0.1752 - acc: 0.9505 - val_loss: 0.6507 - val_acc: 0.7772\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1217 - acc: 0.9718 - val_loss: 0.6581 - val_acc: 0.7781\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1116 - acc: 0.9747 - val_loss: 0.6700 - val_acc: 0.7785\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1018 - acc: 0.9778 - val_loss: 0.6836 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 12th grain: f1_score - 0.654881925198063, acc - 0.7873333333333333\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.4674 - acc: 0.8488 - val_loss: 0.5126 - val_acc: 0.8221\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 26s 246us/step - loss: 0.2947 - acc: 0.9081 - val_loss: 0.5022 - val_acc: 0.8255\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.2176 - acc: 0.9360 - val_loss: 0.5087 - val_acc: 0.8271\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.1562 - acc: 0.9572 - val_loss: 0.5324 - val_acc: 0.8257\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.1077 - acc: 0.9732 - val_loss: 0.5635 - val_acc: 0.8223\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.0684 - acc: 0.9863 - val_loss: 0.5791 - val_acc: 0.8233\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 26s 247us/step - loss: 0.0614 - acc: 0.9882 - val_loss: 0.5923 - val_acc: 0.8221\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 26s 246us/step - loss: 0.0546 - acc: 0.9901 - val_loss: 0.6076 - val_acc: 0.8203\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 13th grain: f1_score - 0.621133864743758, acc - 0.8271333333333334\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 245us/step - loss: 0.9552 - acc: 0.6388 - val_loss: 0.7506 - val_acc: 0.7295\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.6206 - acc: 0.7712 - val_loss: 0.7179 - val_acc: 0.7427\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.5091 - acc: 0.8147 - val_loss: 0.7165 - val_acc: 0.7441\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.4141 - acc: 0.8564 - val_loss: 0.7276 - val_acc: 0.7402\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.3262 - acc: 0.8956 - val_loss: 0.7526 - val_acc: 0.7384\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.2471 - acc: 0.9291 - val_loss: 0.7903 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 243us/step - loss: 0.1735 - acc: 0.9600 - val_loss: 0.8051 - val_acc: 0.7341\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 26s 245us/step - loss: 0.1593 - acc: 0.9647 - val_loss: 0.8194 - val_acc: 0.7341\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 26s 248us/step - loss: 0.1457 - acc: 0.9693 - val_loss: 0.8318 - val_acc: 0.7321\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 14th grain: f1_score - 0.6147748295199377, acc - 0.7441333333333333\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.7739 - acc: 0.6672 - val_loss: 0.6861 - val_acc: 0.6954\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 26s 246us/step - loss: 0.5728 - acc: 0.7602 - val_loss: 0.6595 - val_acc: 0.7115\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.4745 - acc: 0.8119 - val_loss: 0.6576 - val_acc: 0.7168\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.3883 - acc: 0.8571 - val_loss: 0.6772 - val_acc: 0.7143\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.3055 - acc: 0.8995 - val_loss: 0.6996 - val_acc: 0.7135\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.2286 - acc: 0.9354 - val_loss: 0.7467 - val_acc: 0.7072\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.1562 - acc: 0.9682 - val_loss: 0.7568 - val_acc: 0.7075\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1421 - acc: 0.9724 - val_loss: 0.7718 - val_acc: 0.7063\n",
      "Epoch 9/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.1284 - acc: 0.9762 - val_loss: 0.7865 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 15th grain: f1_score - 0.5872625308286522, acc - 0.7168\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 246us/step - loss: 0.7280 - acc: 0.7348 - val_loss: 0.6483 - val_acc: 0.7714\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.5123 - acc: 0.8163 - val_loss: 0.6359 - val_acc: 0.7768\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.4104 - acc: 0.8561 - val_loss: 0.6407 - val_acc: 0.7809\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.3194 - acc: 0.8940 - val_loss: 0.6603 - val_acc: 0.7751\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 26s 247us/step - loss: 0.2373 - acc: 0.9276 - val_loss: 0.6939 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1628 - acc: 0.9593 - val_loss: 0.7100 - val_acc: 0.7734\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.1487 - acc: 0.9639 - val_loss: 0.7233 - val_acc: 0.7727\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.1348 - acc: 0.9689 - val_loss: 0.7333 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 16th grain: f1_score - 0.4559646917267844, acc - 0.7808666666666667\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 250us/step - loss: 0.4758 - acc: 0.8356 - val_loss: 0.4010 - val_acc: 0.8679\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.3226 - acc: 0.8929 - val_loss: 0.3896 - val_acc: 0.8763\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2496 - acc: 0.9194 - val_loss: 0.3975 - val_acc: 0.8741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.1829 - acc: 0.9435 - val_loss: 0.4000 - val_acc: 0.8753\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.1259 - acc: 0.9643 - val_loss: 0.4232 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.0796 - acc: 0.9816 - val_loss: 0.4316 - val_acc: 0.8742\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 26s 245us/step - loss: 0.0711 - acc: 0.9842 - val_loss: 0.4432 - val_acc: 0.8738\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.0630 - acc: 0.9867 - val_loss: 0.4553 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 17th grain: f1_score - 0.6247996903203215, acc - 0.8762666666666666\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 26s 246us/step - loss: 0.6132 - acc: 0.7654 - val_loss: 0.6059 - val_acc: 0.7578\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.4761 - acc: 0.8244 - val_loss: 0.5970 - val_acc: 0.7645\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.3921 - acc: 0.8647 - val_loss: 0.6063 - val_acc: 0.7640\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 239us/step - loss: 0.3129 - acc: 0.9011 - val_loss: 0.6306 - val_acc: 0.7623\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.2374 - acc: 0.9322 - val_loss: 0.6607 - val_acc: 0.7550\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1657 - acc: 0.9621 - val_loss: 0.6754 - val_acc: 0.7577\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1514 - acc: 0.9666 - val_loss: 0.6879 - val_acc: 0.7569\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1376 - acc: 0.9708 - val_loss: 0.7009 - val_acc: 0.7556\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 18th grain: f1_score - 0.4993334831158131, acc - 0.7645333333333333\n",
      "Train on 105000 samples, validate on 15000 samples\n",
      "Epoch 1/30\n",
      "105000/105000 [==============================] - 27s 253us/step - loss: 0.6267 - acc: 0.7484 - val_loss: 0.5663 - val_acc: 0.7846\n",
      "Epoch 2/30\n",
      "105000/105000 [==============================] - 26s 243us/step - loss: 0.4629 - acc: 0.8247 - val_loss: 0.5396 - val_acc: 0.8001\n",
      "Epoch 3/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.3699 - acc: 0.8655 - val_loss: 0.5410 - val_acc: 0.8008\n",
      "Epoch 4/30\n",
      "105000/105000 [==============================] - 25s 240us/step - loss: 0.2809 - acc: 0.9067 - val_loss: 0.5535 - val_acc: 0.7980\n",
      "Epoch 5/30\n",
      "105000/105000 [==============================] - 26s 244us/step - loss: 0.2027 - acc: 0.9412 - val_loss: 0.5843 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "Epoch 6/30\n",
      "105000/105000 [==============================] - 25s 238us/step - loss: 0.1354 - acc: 0.9694 - val_loss: 0.5881 - val_acc: 0.7954\n",
      "Epoch 7/30\n",
      "105000/105000 [==============================] - 25s 242us/step - loss: 0.1229 - acc: 0.9728 - val_loss: 0.5974 - val_acc: 0.7939\n",
      "Epoch 8/30\n",
      "105000/105000 [==============================] - 25s 241us/step - loss: 0.1107 - acc: 0.9765 - val_loss: 0.6082 - val_acc: 0.7929\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "The 19th grain: f1_score - 0.5776658491197562, acc - 0.8008\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8e7a32b04949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_with_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_with_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_with_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLABELS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/mounted/projects/ai_challenger_sentiment/models/linxi.py\u001b[0m in \u001b[0;36mtrain_CNN\u001b[0;34m(train, val, test, y_cols, debug)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All f1 score: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mF1_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "res = train_CNN(train_with_seq, val_with_seq, test_with_seq, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 0th grain: f1_score - 0.5239356264879911, acc - 0.9397333333333333\n",
      "The 1th grain: f1_score - 0.40497252271296214, acc - 0.8820666666666667\n",
      "The 2th grain: f1_score - 0.612868189462613, acc - 0.9072\n",
      "The 3th grain: f1_score - 0.5506936289072112, acc - 0.9047333333333333\n",
      "The 4th grain: f1_score - 0.7117651458401676, acc - 0.8156666666666667\n",
      "The 5th grain: f1_score - 0.6417282220018753, acc - 0.9710666666666666\n",
      "The 6th grain: f1_score - 0.6379514927788742, acc - 0.9190666666666667\n",
      "The 7th grain: f1_score - 0.6924958257313685, acc - 0.7474666666666666\n",
      "The 8th grain: f1_score - 0.6320237658792794, acc - 0.8724666666666666\n",
      "The 9th grain: f1_score - 0.590760787418048, acc - 0.8244\n",
      "The 10th grain: f1_score - 0.614425835543109, acc - 0.8291333333333334\n",
      "The 11th grain: f1_score - 0.6451429332003532, acc - 0.8332666666666667\n",
      "The 12th grain: f1_score - 0.654881925198063, acc - 0.7873333333333333\n",
      "The 13th grain: f1_score - 0.621133864743758, acc - 0.8271333333333334\n",
      "The 14th grain: f1_score - 0.6147748295199377, acc - 0.7441333333333333\n",
      "The 15th grain: f1_score - 0.5872625308286522, acc - 0.7168\n",
      "The 16th grain: f1_score - 0.4559646917267844, acc - 0.7808666666666667\n",
      "The 17th grain: f1_score - 0.6247996903203215, acc - 0.8762666666666666\n",
      "The 18th grain: f1_score - 0.4993334831158131, acc - 0.7645333333333333\n",
      "The 19th grain: f1_score - 0.5776658491197562, acc - 0.8008\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-da0405e42bf0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The %sth grain: f1_score - %s, acc - %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_pred\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All f1 score: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mF1_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_cols' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "F1_scores = 0\n",
    "res = test.copy()\n",
    "for index, col in enumerate(LABELS):\n",
    "    val_y = val[col] + 2\n",
    "    model_file = os.path.join(SAVED_MODELS_PATH, 'linxi/cnn_') + str(index) \n",
    "    model = load_model(model_file)\n",
    "    y_test_prob = model.predict(np.array(test_with_seq[\"word_seq\"].values.tolist()))\n",
    "    y_val_prob = model.predict(np.array(val_with_seq[\"word_seq\"].values.tolist()))\n",
    "    y_test_pred = np.argmax(y_test_prob, axis = 1)\n",
    "    y_val_pred = np.argmax(y_val_prob, axis = 1)\n",
    "    F1_score = f1_score(val_y, y_val_pred, average = 'macro')\n",
    "    F1_scores += F1_score\n",
    "    print(\"The %sth grain: f1_score - %s, acc - %s\" % (index, F1_score, accuracy_score(val_y, y_val_pred)))\n",
    "    res[col] = y_test_pred - 2\n",
    "print('All f1 score: %s' % (F1_scores / len(LABELS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.to_csv(RESULT_CSV, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All f1 score: 0.5947290420268468\n"
     ]
    }
   ],
   "source": [
    "print('All f1 score: %s' % (F1_scores / len(LABELS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
